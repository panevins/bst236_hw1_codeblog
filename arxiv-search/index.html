<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 3/31/2025, 1:22:46 AM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>Optimal treatment regimes for the net benefit of a treatment</h3>
                    <p><strong>Authors:</strong> François Petit, Gérard Biau, Raphaël Porcher</p>
                    <p>  We developed a mathematical setup inspired by Buyse's generalized pairwise
comparisons to define a notion of optimal individualized treatment rule (ITR)
in the presence of prioritized outcomes in a randomized controlled trial,
terming such an ITR pairwise optimal. We present two approaches to estimate
pairwise optimal ITRs. The first is a variant of the k-nearest neighbors
algorithm. The second is a meta-learner based on a randomized bagging scheme,
allowing the use of any classification algorithm for constructing an ITR. We
study the behavior of these estimation schemes from a theoretical standpoint
and through Monte Carlo simulations and illustrate their use on trial data.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.22580v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Comparing methods to assess treatment effect heterogeneity in general
  parametric regression models</h3>
                    <p><strong>Authors:</strong> Yao Chen, Sophie Sun, Konstantinos Sechidis, Cong Zhang, Torsten Hothorn, Björn Bornkamp</p>
                    <p>  This paper reviews and compares methods to assess treatment effect
heterogeneity in the context of parametric regression models. These methods
include the standard likelihood ratio tests, bootstrap likelihood ratio tests,
and Goeman's global test motivated by testing whether the random effect
variance is zero. We place particular emphasis on tests based on the
score-residual of the treatment effect and explore different variants of tests
in this class. All approaches are compared in a simulation study, and the
approach based on residual scores is illustrated in a study comparing multiple
doses versus placebo. Our findings demonstrate that score-residual based
methods provide practical, flexible and reliable tools for identifying
treatment effect heterogeneity and treatment effect modifiers, and can provide
useful guidance for decision making around treatment effect heterogeneity.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.22548v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>An integrated method for clustering and association network inference</h3>
                    <p><strong>Authors:</strong> Jeanne Tous, Julien Chiquet</p>
                    <p>  We consider high dimensional Gaussian graphical models inference. These
models provide a rigorous framework to describe a network of statistical
dependencies between entities, such as genes in genomic regulation studies or
species in ecology. Penalized methods, including the standard Graphical-Lasso,
are well-known approaches to infer the parameters of these models. As the
number of variables in the model (of entities in the network) grow, the network
inference and interpretation become more complex. We propose Normal-Block, a
new model that clusters variables and consider a network at the cluster level.
Normal-Block both adds structure to the network and reduces its size. We build
on Graphical-Lasso to add a penalty on the network's edges and limit the
detection of spurious dependencies, we also propose a zero-inflated version of
the model to account for real-world data properties. For the inference
procedure, we propose a direct heuristic method and another more rigorous one
that simultaneously infers the clustering of variables and the association
network between clusters, using a penalized variational
Expectation-Maximization approach. An implementation of the model in R, in a
package called normalblockr, is available on github
(https://github.com/jeannetous/normalblockr). We present the results in terms
of clustering and network inference using both simulated data and various types
of real-world data (proteomics, words occurrences on webpages, and microbiota
distribution).
</p>
                    <p><a href="http://arxiv.org/pdf/2503.22467v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Estimation of Building Energy Demand Characteristics using Bayesian
  Statistics and Energy Signature Models</h3>
                    <p><strong>Authors:</strong> Justinas Smertinas, Nicolaj Hans Nielsen, Matthias Y. C. Van Hove, Peder Bacher, Henrik Madsen</p>
                    <p>  This work presents a scalable Bayesian modeling framework for evaluating
building energy performance using smart-meter data from 2,788 Danish
single-family homes. The framework leverages Bayesian statistical inference
integrated with Energy Signature (ES) models to characterize thermal
performance in buildings. This approach quantifies key parameters such as the
Heat Loss Coefficient (HLC), solar gain, and wind infiltration, while providing
full posterior distributions to reflect parameter uncertainty.
  Three model variants are developed: a baseline ES model, an auto-regressive
model (ARX-ES) to account for thermal inertia, and an auto-regressive moving
average model (ARMAX-ES) that approximates stochastic gray-box dynamics.
Results show that model complexity improves one-step-ahead predictive
performance, with the ARMAX-ES model achieving a median Bayesian R^2 of 0.94
across the building stock. At the single-building level, the Bayesian approach
yields credible intervals for yearly energy demand within $\pm1\%$, enabling
more robust diagnostics than deterministic methods.
  Beyond improved accuracy, the Bayesian framework enhances decision-making by
explicitly representing uncertainty in building performance parameters. This
provides a more realistic foundation for investment prioritization, demand
forecasting, and long-term energy planning. The method is readily applicable to
other building typologies or geographies, offering a scalable tool for
data-driven energy management under uncertainty.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.22321v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Hierarchical models for small area estimation using zero-inflated forest
  inventory variables: comparison and implementation</h3>
                    <p><strong>Authors:</strong> Grayson W. White, Andrew O. Finley, Josh K. Yamamoto, Jennifer L. Green, Tracey S. Frescino, Hans-Erik Andersen</p>
                    <p>  National Forest Inventory (NFI) data are typically limited to sparse networks
of sample locations due to cost constraints. While traditional design-based
estimators provide reliable forest parameter estimates for large areas, there
is increasing interest in model-based small area estimation (SAE) methods to
improve precision for smaller spatial, temporal, or biophysical domains. SAE
methods can be broadly categorized into area- and unit-level models, with
unit-level models offering greater flexibility -- making them the focus of this
study. Ensuring valid inference requires satisfying model distributional
assumptions, which is particularly challenging for NFI variables that exhibit
positive support and zero inflation, such as forest biomass, carbon, and
volume. Here, we evaluate a class of two-stage unit-level hierarchical Bayesian
models for estimating forest biomass at the county-level in Washington and
Nevada, United States. We compare these models to simpler Bayesian single-stage
and two-stage frequentist approaches. To assess estimator performance, we
employ simulated populations and cross-validation techniques. Results indicate
that small area estimators that incorporate a two-stage approach to account for
zero inflation, county-specific random intercepts and residual variances, and
spatial random effects provide the most reliable county-level estimates.
Additionally, findings suggest that unit-level cross-validation within the
training dataset is as effective as area-level validation using simulated
populations for model selection. We also illustrate the usefulness of simulated
populations for better assessing qualities of the various estimators
considered.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.22103v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Parapolitics and Roll-Call Voting in Colombia: A Bayesian Euclidean and
  Spherical Spatial Analysis</h3>
                    <p><strong>Authors:</strong> Juan Sosa, Carolina Luque, Juan Valero</p>
                    <p>  This study presents a Bayesian spatial voting analysis of the Colombian
Senate during the 2006-2010 legislative period, leveraging a newly constructed
roll-call dataset comprising 147 senators and 136 plenary votes. We estimate
legislators' ideal points under two alternative geometric frameworks: A
traditional Euclidean model and a circular model that embeds preferences on the
unit circle. Both models are implemented using Markov Chain Monte Carlo
methods, with the circular specification capturing geodesic distances and von
Mises-distributed latent traits. The results reveal a latent structure in
voting behavior best characterized not by a conventional left-right ideological
continuum but by an opposition-non-opposition alignment. Using Bayesian
logistic regression, we further investigate the association between senators'
ideal points and their involvement in the para-politics scandal. Findings
indicate a significant and robust relationship between political alignment and
para-politics implication, suggesting that extralegal influence was
systematically related to senators' legislative behavior during this period.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.22045v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A Semiparametric Quantile Single-Index Model for Zero-Inflated Outcomes</h3>
                    <p><strong>Authors:</strong> Zirui Wang, Tianying Wang</p>
                    <p>  We consider the complex data modeling problem motivated by the zero-inflated
and overdispersed data from microbiome studies. Analyzing how microbiome
abundance is associated with human biological features, such as BMI, is of
great importance for host health. Methods based on parametric distributional
assumptions, such as zero-inflated Poisson and zero-inflated Negative Binomial
regression, have been widely used in modeling such data, yet the parametric
assumptions are restricted and hard to verify in real-world applications. We
relax the parametric assumptions and propose a semiparametric single-index
quantile regression model. It is flexible to include a wide range of possible
association functions and adaptable to the various zero proportions across
subjects, which relaxes the strong parametric distributional assumptions of
most existing zero-inflated data modeling approaches. We establish the
asymptotic properties for the index coefficients estimator and quantile
regression curve estimation. Through extensive simulation studies, we
demonstrate the superior performance of the proposed method regarding model
fitting.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.21924v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A novel smoothing-based goodness-of-fit test of covariance for
  multivariate sparse functional data</h3>
                    <p><strong>Authors:</strong> Dhrubajyoti Ghosh, Zhuolin Song, Luo Xiao, Sheng Luo</p>
                    <p>  Accurately specifying covariance structures is critical for valid inference
in longitudinal and functional data analysis, particularly when data are
sparsely observed. In this study, we develop a global goodness-of-fit test to
assess parametric covariance structures in multivariate sparse functional data.
Our contribution is twofold. First, we extend the univariate goodness-of-fit
test proposed by Chen et al. (2019) to better accommodate sparse data by
improving error variance estimation and applying positive semi-definite
smoothing to covariance estimation. These corrections ensure appropriate Type I
error control under sparse designs. Second, we introduce a multivariate
extension of the improved test that jointly evaluates covariance structures
across multiple outcomes, employing novel test statistics based on the maximum
and $\ell_2$ norms to account for inter-outcome dependencies and enhance
statistical power. Through extensive simulation studies, we demonstrate that
the proposed methods maintain proper Type I error rates and achieve greater
power than univariate tests with multiple testing adjustments. Applications to
longitudinal neuroimaging and clinical data from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) and the Parkinson's Progression Marker
Initiative (PPMI) illustrate the practical utility of the proposed methods for
evaluating covariance structures in sparse multivariate longitudinal data.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.21913v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Investigating Experiential Effects in Online Chess using a Hierarchical
  Bayesian Analysis</h3>
                    <p><strong>Authors:</strong> Adam Gee, Sydney O. Seese, James P. Curley, Owen G. Ward</p>
                    <p>  The presence or absence of winner-loser effects is a widely discussed
phenomenon across both sports and psychology research. Investigation of such
effects is often hampered by the limited availability of data. Online chess has
exploded in popularity in recent years and provides vast amounts of data which
can be used to explore this question. With a hierarchical Bayesian regression
model, we carefully investigate the presence of such experiential effects in
online chess. Using a large quantity of online chess data, we see little
evidence for experiential effects that are consistent across all players, with
some individual players showing some evidence for such effects. Given the
challenging temporal nature of this data, we discuss several methods for
assessing the suitability of our model and carefully check its validity.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.21713v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Unlocking the Potential of Past Research: Using Generative AI to
  Reconstruct Healthcare Simulation Models</h3>
                    <p><strong>Authors:</strong> Thomas Monks, Alison Harper, Amy Heather</p>
                    <p>  Discrete-event simulation (DES) is widely used in healthcare Operations
Research, but the models themselves are rarely shared. This limits their
potential for reuse and long-term impact in the modelling and healthcare
communities. This study explores the feasibility of using generative artificial
intelligence (AI) to recreate published models using Free and Open Source
Software (FOSS), based on the descriptions provided in an academic journal.
Using a structured methodology, we successfully generated, tested and
internally reproduced two DES models, including user interfaces. The reported
results were replicated for one model, but not the other, likely due to missing
information on distributions. These models are substantially more complex than
AI-generated DES models published to date. Given the challenges we faced in
prompt engineering, code generation, and model testing, we conclude that our
iterative approach to model development, systematic comparison and testing, and
the expertise of our team were necessary to the success of our recreated
simulation models.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.21646v1" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>