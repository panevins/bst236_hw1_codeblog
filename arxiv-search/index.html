<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 5/12/2025, 1:24:21 AM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>Diffusion piecewise exponential models for survival extrapolation using
  Piecewise Deterministic Monte Carlo</h3>
                    <p><strong>Authors:</strong> Luke Hardcastle, Samuel Livingstone, Gianluca Baio</p>
                    <p>  The piecewise exponential model is a flexible non-parametric approach for
time-to-event data, but extrapolation beyond final observation times typically
relies on random walk priors and deterministic knot locations, resulting in
unrealistic long-term hazards. We introduce the diffusion piecewise exponential
model, a prior framework consisting of a discretised diffusion for the hazard,
that can encode a wide variety of information about the long-term behaviour of
the hazard, time changed by a Poisson process prior for knot locations. This
allows the behaviour of the hazard in the observation period to be combined
with prior information to inform extrapolations. Efficient posterior sampling
is achieved using Piecewise Deterministic Markov Processes, whereby we extend
existing approaches using sticky dynamics from sampling spike-and-slab
distributions to more general transdimensional posteriors. We focus on
applications in Health Technology Assessment, where the need to compute mean
survival requires hazard functions to be extrapolated beyond the observation
period, showcasing performance on datasets for Colon cancer and Leukaemia
patients.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05932v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Who's at Risk? Effects of Inflation on Unemployment Risk</h3>
                    <p><strong>Authors:</strong> Hie Joo Ahn, Lam Nguyen</p>
                    <p>  We empirically investigate the distributional effects of inflation on
workers' unemployment tail risks using instrumental variable quantile
regression. We find that supply-driven inflation disproportionately raises
unemployment tail risks for cyclically vulnerable workers in both the short and
medium term, while demand-driven inflation has differential effects -- limited
to race and reason for unemployment -- only in the medium term. Demand-boosting
policies, including monetary policy, can inadvertently widen those disparities
through the inflation channel, underscoring the importance of inflation
stabilization in promoting equitable growth in the labor market. Our findings
could be explained structurally by heterogeneity in experienced inflation and
wage inflation expectations.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05757v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Bayesian shape-constrained regression for quantifying Alzheimer's
  disease biomarker progression</h3>
                    <p><strong>Authors:</strong> Mingyuan Li, Zheyu Wang, Akihiko Nishimura</p>
                    <p>  Several biomarkers are hypothesized to indicate early stages of Alzheimer's
disease, well before the cognitive symptoms manifest. Their precise relations
to the disease progression, however, is poorly understood. This lack of
understanding limits our ability to diagnose the disease and intervene
effectively at early stages. To provide better understanding of the relation
between the disease and biomarker progressions, we propose a novel modeling
approach to quantify the biomarkers' trajectories as functions of age. Building
on monotone regression splines, we introduce two additional shape constraints
to incorporate structures informed by the current medical literature. First, we
impose the regression curves to satisfy a vanishing derivative condition,
reflecting the observation that changes in biomarkers generally plateau at
early and late stages of the disease. Second, we enforce the regression curves
to have a unique inflection point, which enhances interpretability of the
estimated disease progression and facilitates assessment of temporal ordering
among the biomarkers. We fit our shape-constrained regression model under
Bayesian framework to take advantage of its ability to account for the
heterogeneity in disease progression among individuals. When applied to the
BIOCARD data, the model is able to capture asymmetry in the biomarkers'
progressions while maintaining interpretability, yielding estimates of the
curves with temporal ordering consistent with the existing scientific
hypotheses.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05700v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Estimation and Inference in Boundary Discontinuity Designs</h3>
                    <p><strong>Authors:</strong> Matias D. Cattaneo, Rocio Titiunik, Ruiqi Rae Yu</p>
                    <p>  Boundary Discontinuity Designs are used to learn about treatment effects
along a continuous boundary that splits units into control and treatment groups
according to a bivariate score variable. These research designs are also called
Multi-Score Regression Discontinuity Designs, a leading special case being
Geographic Regression Discontinuity Designs. We study the statistical
properties of commonly used local polynomial treatment effects estimators along
the continuous treatment assignment boundary. We consider two distinct
approaches: one based explicitly on the bivariate score variable for each unit,
and the other based on their univariate distance to the boundary. For each
approach, we present pointwise and uniform estimation and inference methods for
the treatment effect function over the assignment boundary. Notably, we show
that methods based on univariate distance to the boundary exhibit an
irreducible large misspecification bias when the assignment boundary has kinks
or other irregularities, making the distance-based approach unsuitable for
empirical work in those settings. In contrast, methods based on the bivariate
score variable do not suffer from that drawback. We illustrate our methods with
an empirical application. Companion general-purpose software is provided.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05670v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>The Evolution of Embedding Table Optimization and Multi-Epoch Training
  in Pinterest Ads Conversion</h3>
                    <p><strong>Authors:</strong> Andrew Qiu, Shubham Barhate, Hin Wai Lui, Runze Su, Rafael Rios MÃ¼ller, Kungang Li, Ling Leng, Han Sun, Shayan Ehsani, Zhifang Liu</p>
                    <p>  Deep learning for conversion prediction has found widespread applications in
online advertising. These models have become more complex as they are trained
to jointly predict multiple objectives such as click, add-to-cart, checkout and
other conversion types. Additionally, the capacity and performance of these
models can often be increased with the use of embedding tables that encode high
cardinality categorical features such as advertiser, user, campaign, and
product identifiers (IDs). These embedding tables can be pre-trained, but also
learned end-to-end jointly with the model to directly optimize the model
objectives. Training these large tables is challenging due to: gradient
sparsity, the high cardinality of the categorical features, the non-uniform
distribution of IDs and the very high label sparsity. These issues make
training prone to both slow convergence and overfitting after the first epoch.
Previous works addressed the multi-epoch overfitting issue by using: stronger
feature hashing to reduce cardinality, filtering of low frequency IDs,
regularization of the embedding tables, re-initialization of the embedding
tables after each epoch, etc. Some of these techniques reduce overfitting at
the expense of reduced model performance if used too aggressively. In this
paper, we share key learnings from the development of embedding table
optimization and multi-epoch training in Pinterest Ads Conversion models. We
showcase how our Sparse Optimizer speeds up convergence, and how multi-epoch
overfitting varies in severity between different objectives in a multi-task
model depending on label sparsity. We propose a new approach to deal with
multi-epoch overfitting: the use of a frequency-adaptive learning rate on the
embedding tables and compare it to embedding re-initialization. We evaluate
both methods offline using an industrial large-scale production dataset.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05605v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation
  Statistics</h3>
                    <p><strong>Authors:</strong> Lennart Luettgau, Harry Coppock, Magda Dubois, Christopher Summerfield, Cozmin Ududec</p>
                    <p>  As Large Language Models (LLMs) and other AI systems evolve, robustly
estimating their capabilities from inherently stochastic outputs while
systematically quantifying uncertainty in these estimates becomes increasingly
important. Further, advanced AI evaluations often have a nested hierarchical
structure, exhibit high levels of complexity, and come with high costs in
testing the most advanced AI systems. To address these challenges, we introduce
HiBayES, a generalizable Hierarchical Bayesian modeling framework for AI
Evaluation Statistics. HiBayES supports robust inferences in classical
question-answer benchmarks and advanced agentic evaluations, particularly in
low-data scenarios (e.g., < 20 data points per evaluation). Built on
Generalized Linear Models (GLMs), Bayesian data analysis, and formal model
comparison, HiBayES provides principled uncertainty quantification and robust
parameter estimation. This paper offers a comprehensive introduction to
HiBayES, including illustrative examples, comparisons to conventional
statistical methods, and practical guidance for implementing multilevel
Bayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta
version) for out-of-the-box implementation.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05602v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Machine learning bridging battery field data and laboratory data</h3>
                    <p><strong>Authors:</strong> Yanbin Zhao, Hao Liu, Zhihua Deng, Tong Li, Haoyi Jiang, Zhenfei Ling, Xingkai Wang, Lei Zhang, Xiaoping Ouyang</p>
                    <p>  Aiming at the dilemma that most laboratory data-driven diagnostic and
prognostic methods cannot be applied to field batteries in passenger cars and
energy storage systems, this paper proposes a method to bridge field data and
laboratory data using machine learning. Only two field real impedances
corresponding to a medium frequency and a high frequency are needed to predict
laboratory real impedance curve, laboratory charge/discharge curve, and
laboratory relaxation curve. Based on the predicted laboratory data, laboratory
data-driven methods can be used for field battery diagnosis and prognosis.
Compared with the field data-driven methods based on massive historical field
data, the proposed method has the advantages of higher accuracy, lower cost,
faster speed, readily available, and no use of private data. The proposed
method is tested using two open-source datasets containing 249 NMC cells. For a
test set containing 76 cells, the mean absolute percentage errors of laboratory
real impedance curve, charge curve, and discharge curve prediction results are
0.85%, 4.72%, and 2.69%, respectively. This work fills the gap between
laboratory data-driven diagnostic and prognostic methods and field battery
applications, making all laboratory data-driven methods applicable to field
battery diagnosis and prognosis. Furthermore, this work overturns the fixed
path of developing field battery diagnostic and prognostic methods based on
massive field historical data, opening up new research and breakthrough
directions for field battery diagnosis and prognosis.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05364v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Modeling the 2022 Mpox Outbreak with a Mechanistic Network Model</h3>
                    <p><strong>Authors:</strong> Emma G. Crenshaw, Jukka-Pekka Onnela</p>
                    <p>  We implemented a dynamic agent-based network model to simulate the spread of
mpox in a United States-based MSM population. This model allowed us to
implement data-informed dynamic network evolution to simulate realistic disease
spreading and behavioral adaptations. We found that behavior change, the
reduction in one-time partnerships, and widespread vaccination are effective in
preventing the transmission of mpox and that earlier intervention has a greater
effect, even when only a high-risk portion of the population participates. With
no intervention, 16% of the population was infected (25th percentile, 75th
percentiles of simulations: 15.3%, 16.6%). With vaccination and behavior change
in only the 25% of individuals most likely to have a one-time partner,
cumulative infections were reduced by 30%, or a total reduction in nearly 500
infections. Earlier intervention further reduces cumulative infections;
beginning vaccination a year before the outbreak results in only 5.5% of men
being infected, averting 950 infections or nearly 10% of the total population
in our model. We also show that sustained partnerships drive the early
outbreak, while one-time partnerships drive transmission after the first
initial weeks. The median effective reproductive number, Rt, at t = 0 days is
1.30 for casual partnerships, 1.00 for main, and 0.6 for one-time. By t = 28,
the median Rt for one-time partnerships has more than doubled to 1.48, while it
decreased for casual and main partnerships: 0.46 and 0.29, respectively. With
the ability to model individuals' behavior, mechanistic networks are
particularly well suited to studying sexually transmitted infections, the
spread and control of which are often governed by individual-level action. Our
results contribute valuable insights into the role of different interventions
and relationship types in mpox transmission dynamics.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05534v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Simulating MLB Seasons using Bayesian Inference and Random Walks</h3>
                    <p><strong>Authors:</strong> Simon Cha</p>
                    <p>  As a dedicated follower of sports statistics and with the MLB season
beginning in late March, I set out to predict how many wins each team would
accumulate by the end of the 162 game season. The goal was to build a
simulation framework capable of forecasting the remainder of the season,
starting from a 20 game burn-in period to establish initial estimates of team
strength. My approach used a Bayesian inference model incorporating team win
percentage, batting average, and pitching ERA to construct a posterior
distribution of win probability for each matchup. For each game, I sampled from
the posterior and simulated the outcome using a Bernoulli trial. Because future
matchup inputs were unobserved, I forecasted batting averages using random
walks and modeled pitching ERA with Kalman filters. After simulating many
seasons, the model produced a distribution of win totals for all 30 teams and
can also be used to estimate each team's probability of making the postseason.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05120v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Modeling electrical distribution networks with inhomogeneous
  Galton-Watson trees</h3>
                    <p><strong>Authors:</strong> Jakob G. Rasmussen, Troels Pedersen, Rasmus L. Olsen</p>
                    <p>  In this paper we consider inhomogeneous Galton-Watson trees, and derive
various moments for such processes: the number of vertices, the number of
leaves, and the height of the tree. Also we make a simple condition of
finiteness. We use these processes to model a data set consisting of electrical
distribution networks, where we make a flexible framework for formulating
models through the mean and variance of the offspring distributions.
Furthermore, we introduce two mixture distributions as offspring distributions
to reflect the particular form of the data. For estimation we use maximum
likelihood estimation.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.05092v1" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>