<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 9/22/2025, 1:22:52 AM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>KRED: Korea Research Economic Database for Macroeconomic Research</h3>
                    <p><strong>Authors:</strong> Changryong Baek, Seunghyun Moon, Seunghyeon Lee</p>
                    <p>  We introduce KRED (Korea Research Economic Database), a new FRED MD style
macroeconomic dataset for South Korea. KRED is constructed by aggregating 88
key monthly time series from multiple official sources (e.g., Bank of Korea
ECOS, Statistics Korea KOSIS) into a unified, publicly available database. The
dataset is aligned with the FRED MD format, enabling standardized
transformations and direct comparability; an Appendix maps each Korean series
to its FRED MD counterpart. Using a balanced panel of 80 series from 2009 to
2024, we extract four principal components via PCA that explain approximately
40% of the total variance. These four factors have intuitive economic
interpretations, capturing monetary conditions, labor market activity, real
output, and housing demand, analogous to diffusion indexes summarizing broad
economic movements. Notably, the factor based diffusion indexes derived from
KRED clearly trace major macroeconomic fluctuations over the sample period such
as the 2020 COVID 19 recession. Our results demonstrate that KRED's factor
structure can effectively condense complex economic information into a few
informative indexes, yielding new insights into South Korea's business cycles
and co movements.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.16115v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Beyond the Average: Distributional Causal Inference under Imperfect
  Compliance</h3>
                    <p><strong>Authors:</strong> Undral Byambadalai, Tomu Hirata, Tatsushi Oka, Shota Yasui</p>
                    <p>  We study the estimation of distributional treatment effects in randomized
experiments with imperfect compliance. When participants do not adhere to their
assigned treatments, we leverage treatment assignment as an instrumental
variable to identify the local distributional treatment effect-the difference
in outcome distributions between treatment and control groups for the
subpopulation of compliers. We propose a regression-adjusted estimator based on
a distribution regression framework with Neyman-orthogonal moment conditions,
enabling robustness and flexibility with high-dimensional covariates. Our
approach accommodates continuous, discrete, and mixed discrete-continuous
outcomes, and applies under a broad class of covariate-adaptive randomization
schemes, including stratified block designs and simple random sampling. We
derive the estimator's asymptotic distribution and show that it achieves the
semiparametric efficiency bound. Simulation results demonstrate favorable
finite-sample performance, and we demonstrate the method's practical relevance
in an application to the Oregon Health Insurance Experiment.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.15594v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Direct Estimation of Eigenvalues of Large Dimensional Precision Matrix</h3>
                    <p><strong>Authors:</strong> Jie Zhou, Junhao Xie, Jiaqi Chen</p>
                    <p>  In this paper, we consider directly estimating the eigenvalues of precision
matrix, without inverting the corresponding estimator for the eigenvalues of
covariance matrix. We focus on a general asymptotic regime, i.e., the large
dimensional regime, where both the dimension $N$ and the sample size $K$ tend
to infinity whereas their quotient $N/K$ converges to a positive constant. By
utilizing tools from random matrix theory, we construct an improved estimator
for eigenvalues of precision matrix. We prove the consistency of the new
estimator under large dimensional regime. In order to obtain the asymptotic
bias term of the proposed estimator, we provide a theoretical result that
characterizes the convergence rate of the expected Stieltjes transform (with
its derivative) of the spectra of the sample covariance matrix. Using this
result, we prove that the asymptotic bias term of the proposed estimator is of
order $O(1/K^2)$. Additionally, we establish a central limiting theorem (CLT)
to describe the fluctuations of the new estimator. Finally, some numerical
examples are presented to validate the excellent performance of the new
estimator and to verify the accuracy of the CLT.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.15554v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Diffusion-Based Cross-Modal Feature Extraction for Multi-Label
  Classification</h3>
                    <p><strong>Authors:</strong> Tian Lan, Yiming Zheng, Jianxin Yin</p>
                    <p>  Multi-label classification has broad applications and depends on powerful
representations capable of capturing multi-label interactions. We introduce
\textit{Diff-Feat}, a simple but powerful framework that extracts intermediate
features from pre-trained diffusion-Transformer models for images and text, and
fuses them for downstream tasks. We observe that for vision tasks, the most
discriminative intermediate feature along the diffusion process occurs at the
middle step and is located in the middle block in Transformer. In contrast, for
language tasks, the best feature occurs at the noise-free step and is located
in the deepest block. In particular, we observe a striking phenomenon across
varying datasets: a mysterious "Layer $12$" consistently yields the best
performance on various downstream classification tasks for images (under
DiT-XL/2-256$\times$256). We devise a heuristic local-search algorithm that
pinpoints the locally optimal "image-text"$\times$"block-timestep" pair among a
few candidates, avoiding an exhaustive grid search. A simple fusion-linear
projection followed by addition-of the selected representations yields
state-of-the-art performance: 98.6\% mAP on MS-COCO-enhanced and 45.7\% mAP on
Visual Genome 500, surpassing strong CNN, graph, and Transformer baselines by a
wide margin. t-SNE and clustering metrics further reveal that
\textit{Diff-Feat} forms tighter semantic clusters than unimodal counterparts.
The code is available at https://github.com/lt-0123/Diff-Feat.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.15553v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Manifold Dimension Estimation: An Empirical Study</h3>
                    <p><strong>Authors:</strong> Zelong Bi, Pierre Lafaye de Micheaux</p>
                    <p>  The manifold hypothesis suggests that high-dimensional data often lie on or
near a low-dimensional manifold. Estimating the dimension of this manifold is
essential for leveraging its structure, yet existing work on dimension
estimation is fragmented and lacks systematic evaluation. This article provides
a comprehensive survey for both researchers and practitioners. We review
often-overlooked theoretical foundations and present eight representative
estimators. Through controlled experiments, we analyze how individual factors
such as noise, curvature, and sample size affect performance. We also compare
the estimators on diverse synthetic and real-world datasets, introducing a
principled approach to dataset-specific hyperparameter tuning. Our results
offer practical guidance and suggest that, for a problem of this generality,
simpler methods often perform better.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.15517v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A tree-based kernel for densities and its applications in clustering
  DNase-seq profiles</h3>
                    <p><strong>Authors:</strong> Yuliang Xu, Kaixuan Luo, Li Ma</p>
                    <p>  Modeling multiple sampling densities within a hierarchical framework enables
borrowing of information across samples. These density random effects can act
as kernels in latent variable models to represent exchangeable subgroups or
clusters. A key feature of these kernels is the (functional) covariance they
induce, which determines how densities are grouped in mixture models. Our
motivating problem is clustering chromatin accessibility profiles from
high-throughput DNase-seq experiments to detect transcription factor (TF)
binding. TF binding typically produces footprint profiles with spatial
patterns, creating long-range dependency across genomic locations. Existing
nonparametric hierarchical models impose restrictive covariance assumptions and
cannot accommodate such dependencies, often leading to biologically
uninformative clusters. We propose a nonparametric density kernel flexible
enough to capture diverse covariance structures and adaptive to various spatial
patterns of TF footprints. The kernel specifies dyadic tree splitting
probabilities via a multivariate logit-normal model with a sparse precision
matrix. Bayesian inference for latent variable models using this kernel is
implemented through Gibbs sampling with Polya-Gamma augmentation. Extensive
simulations show that our kernel substantially improves clustering accuracy. We
apply the proposed mixture model to DNase-seq data from the ENCODE project,
which results in biologically meaningful clusters corresponding to binding
events of two common TFs.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.15480v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A Single Index Approach to Integrated Species Distribution Modeling for
  Fisheries Abundance Data</h3>
                    <p><strong>Authors:</strong> Quan Vu, Francis K. C. Hui, A. H. Welsh, Samuel Muller, Eva Cantoni, Christopher R. Haak</p>
                    <p>  In fisheries ecology, species abundance data are often collected by multiple
surveys, each with unique characteristics. This article focuses on Atlantic sea
scallop abundance data along the northeast coast of the United States,
collected from two bottom trawl surveys which cover a larger spatial domain but
have low catch efficiency, and a dredge survey which is more efficient but
limited to domains where the species are believed to be present. To model such
data, integrated species distribution models (ISDMs) have been proposed to
incorporate information from multiple surveys, by including common
environmental effects along with correlated survey-specific spatial fields.
However, while flexible, these ISDMs can be susceptible to overfitting, which
can complicate interpretability of the shared environmental effects and
potentially lead to poor predictive performance. To overcome these drawbacks,
we introduce a novel single index ISDM, built from a single index (with spatial
random effects) that represents a latent measure of the true species
distribution, and survey-specific catch efficiency functions which map the
single index to the survey-specific expected catch. Our results show that the
single index ISDM offers more meaningful interpretations of the environmental
effects and survey catch efficiency differences, while potentially achieving
better predictive performance than existing ISDMs.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.15379v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Explaining deep learning for ECG using time-localized clusters</h3>
                    <p><strong>Authors:</strong> Ahcène Boubekki, Konstantinos Patlatzoglou, Joseph Barker, Fu Siong Ng, Antônio H. Ribeiro</p>
                    <p>  Deep learning has significantly advanced electrocardiogram (ECG) analysis,
enabling automatic annotation, disease screening, and prognosis beyond
traditional clinical capabilities. However, understanding these models remains
a challenge, limiting interpretation and gaining knowledge from these
developments. In this work, we propose a novel interpretability method for
convolutional neural networks applied to ECG analysis. Our approach extracts
time-localized clusters from the model's internal representations, segmenting
the ECG according to the learned characteristics while quantifying the
uncertainty of these representations. This allows us to visualize how different
waveform regions contribute to the model's predictions and assess the certainty
of its decisions. By providing a structured and interpretable view of deep
learning models for ECG, our method enhances trust in AI-driven diagnostics and
facilitates the discovery of clinically relevant electrophysiological patterns.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.15198v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A Latent Principal Stratification Method to Address One-Sided Cluster
  and Individual Noncompliance in Cluster RCTs</h3>
                    <p><strong>Authors:</strong> Anthony Sisti, Ellen McCreedy, Roee Gutman</p>
                    <p>  In pragmatic cluster randomized controlled trials (PCRCTs), the unit of
randomization may be the healthcare provider. In these studies, noncompliance
can occur at both the patient and cluster levels. Some studies measure
cluster-level implementation using multiple continuous metrics while
documenting individual binary compliance. The complier average causal effect
estimates the intervention effects among individuals that comply with the
assigned intervention. However, it does not account for compliance metrics at
the cluster level. When compliance with the intervention is influenced by both
providers and individuals, it can be scientifically beneficial to describe the
effects of the intervention between all levels of compliance. We propose a
Bayesian method for PCRCTs with one-sided binary noncompliance at the
individual level and one-sided partial compliance at the cluster level. Our
Bayesian model classifies clusters into latent compliance strata based on
pretreatment characteristics, partial compliance status, and individual
outcomes. Because compliance is only observed in the treatment arm, the method
imputes unobserved compliance for control clusters and the individuals within
them. This approach estimates finite and super-population estimands within
strata defined by both cluster- and individual-level compliance. We apply this
method to the METRIcAL trial, a multi-part, pragmatic cluster randomized trial
evaluating the effects of a personalized music intervention on agitation in
nursing home residents with dementia.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.15280v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Forecasting in small open emerging economies Evidence from Thailand</h3>
                    <p><strong>Authors:</strong> Paponpat Taveeapiradeecharoen, Nattapol Aunsri</p>
                    <p>  Forecasting inflation in small open economies is difficult because limited
time series and strong external exposures create an imbalance between few
observations and many potential predictors. We study this challenge using
Thailand as a representative case, combining more than 450 domestic and
international indicators. We evaluate modern Bayesian shrinkage and factor
models, including Horseshoe regressions, factor-augmented autoregressions,
factor-augmented VARs, dynamic factor models, and Bayesian additive regression
trees.
  Our results show that factor models dominate at short horizons, when global
shocks and exchange rate movements drive inflation, while shrinkage-based
regressions perform best at longer horizons. These models not only improve
point and density forecasts but also enhance tail-risk performance at the
one-year horizon.
  Shrinkage diagnostics, on the other hand, additionally reveal that Google
Trends variables, especially those related to food essential goods and housing
costs, progressively rotate into predictive importance as the horizon
lengthens. This underscores their role as forward-looking indicators of
household inflation expectations in small open economies.
</p>
                    <p><a href="http://arxiv.org/pdf/2509.14805v1" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>