<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 5/19/2025, 1:23:48 AM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>Mechanistic inference of stochastic gene expression from structured
  single-cell data</h3>
                    <p><strong>Authors:</strong> Christopher E. Miles</p>
                    <p>  Single-cell gene expression measurements encode variability spanning
molecular noise, cellular heterogeneity, and technical artifacts. Mechanistic
models provide a principled framework to disentangle these sources and extract
insight, but inferring underlying dynamics from standard sequencing count data
faces fundamental limitations. Structured datasets with temporal, spatial, or
multimodal features offer constraints that help resolve these ambiguities, but
demand more complex models and advanced inference strategies, including machine
learning techniques with associated tradeoffs. This review highlights recent
progress in the judicious integration of structured single-cell data,
stochastic model development, and innovative inference strategies to extract
gene-level insights. These approaches lay the foundation for mechanistic
understanding of regulatory networks and multicellular systems.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.11460v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A Generative Framework for Causal Estimation via Importance-Weighted
  Diffusion Distillation</h3>
                    <p><strong>Authors:</strong> Xinran Song, Tianyu Chen, Mingyuan Zhou</p>
                    <p>  Estimating individualized treatment effects from observational data is a
central challenge in causal inference, largely due to covariate imbalance and
confounding bias from non-randomized treatment assignment. While inverse
probability weighting (IPW) is a well-established solution to this problem, its
integration into modern deep learning frameworks remains limited. In this work,
we propose Importance-Weighted Diffusion Distillation (IWDD), a novel
generative framework that combines the pretraining of diffusion models with
importance-weighted score distillation to enable accurate and fast causal
estimation-including potential outcome prediction and treatment effect
estimation. We demonstrate how IPW can be naturally incorporated into the
distillation of pretrained diffusion models, and further introduce a
randomization-based adjustment that eliminates the need to compute IPW
explicitly-thereby simplifying computation and, more importantly, provably
reducing the variance of gradient estimates. Empirical results show that IWDD
achieves state-of-the-art out-of-sample prediction performance, with the
highest win rates compared to other baselines, significantly improving causal
estimation and supporting the development of individualized treatment
strategies. We will release our PyTorch code for reproducibility and future
research.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.11444v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>JaxSGMC: Modular stochastic gradient MCMC in JAX</h3>
                    <p><strong>Authors:</strong> Stephan Thaler, Paul Fuchs, Ana Cukarska, Julija Zavadlav</p>
                    <p>  We present JaxSGMC, an application-agnostic library for stochastic gradient
Markov chain Monte Carlo (SG-MCMC) in JAX. SG-MCMC schemes are uncertainty
quantification (UQ) methods that scale to large datasets and high-dimensional
models, enabling trustworthy neural network predictions via Bayesian deep
learning. JaxSGMC implements several state-of-the-art SG-MCMC samplers to
promote UQ in deep learning by reducing the barriers of entry for switching
from stochastic optimization to SG-MCMC sampling. Additionally, JaxSGMC allows
users to build custom samplers from standard SG-MCMC building blocks. Due to
this modular structure, we anticipate that JaxSGMC will accelerate research
into novel SG-MCMC schemes and facilitate their application across a broad
range of domains.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.11190v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Covariance Symmetries Classification in Multitemporal/Multipass PolSAR
  Images</h3>
                    <p><strong>Authors:</strong> Dehbia Hanis, Luca Pallotta, Augusto Aubry, Aichouche Belhadj-Aissa, Antonio De Maio</p>
                    <p>  A polarimetric synthetic aperture radar (PolSAR) system, which uses multiple
images acquired with different polarizations in both transmission and
reception, has the potential to improve the description and interpretation of
the observed scene. This is typically achieved by exploiting the polarimetric
covariance or coherence matrix associated with each pixel, which is processed
to meet a specific goal in Earth observation. This paper presents a design
framework for selecting the structure of the polarimetric covariance matrix
that accurately reflects the symmetry associated with the analyzed pixels. The
proposed methodology leverages both polarimetric and temporal information from
multipass PolSAR images to enhance the retrieval of information from the
acquired data. To accomplish this, it is assumed that the covariance matrix (of
the overall acquired data) is given as the Kronecker product of the temporal
and polarimetric covariances. An alternating maximization algorithm, known as
the flip-flop method, is then developed to estimate both matrices while
enforcing the symmetry constraint on the polarimetric covariance. Subsequently,
the symmetry structure classification is formulated as a multiple hypothesis
testing problem, which is solved using model order selection techniques. The
proposed approach is quantitatively assessed on simulated data, showing its
advantages over its competitor, which does not exploit temporal correlations.
For example, it reaches accuracies of 94.6% and 92.0% for the reflection and
azimuth symmetry classes, respectively, while the competitor achieves 72.5% and
72.6% under the same simulation conditions. Finally, the effectiveness of the
proposed framework is further demonstrated using measured RADARSAT-2 data,
corroborating the results obtained from the simulations.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.11137v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Age-stratified clustering of multiple long-term conditions</h3>
                    <p><strong>Authors:</strong> Anirban Chakraborty, Bruce Guthrie, Sohan Seth</p>
                    <p>  Background: Most people with any long-term condition have multiple long-term
conditions, but our understanding of how conditions cluster is limited. Many
clustering studies identify clusters in the whole population, but the clusters
that occur in people of different ages may be distinct. The aim of this paper
was to explore similarities and differences in clusters found in different
age-groups.
  Method: We present a method for finding similar clusters in multiple
age-groups, referred to as cluster sets, using Latent Class Analysis (LCA) and
Chebyshev distance metric. We analyse a primary care electronic health record
(EHR) dataset recording the presence of 40 long-term conditions (LTCs) in
570,355 people aged 40-99 years with at least one of these conditions,
analysing in five-year age-groups.
  Findings: We find that the 600 clusters found separately in 12 age-strata can
be summarised by 342 cluster sets with 263 cluster sets only being found in a
single age-group (singleton cluster sets), and 79 cluster sets being present in
multiple age-groups. We observe that 31 conditions of the 40 conditions studied
appear in cluster sets with the respective condition being the only condition
present with a very high prevalence of more than 0.9 whereas the remaining
cluster sets typically contain two to four conditions present with a high
prevalence of more than 0.7.
  Interpretation: Multimorbidity profiles in different age-groups are often
distinct (singleton cluster sets observed only in that age-group), but similar
clusters with small variations in their composition are also found in multiple
age-groups. This demonstrates the age dependency of MLTC clusters and presents
a case for age-stratified clustering.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.10952v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Estimating Velocity Vector Fields using Transport Gaussian Processes</h3>
                    <p><strong>Authors:</strong> Youssef Fahmy, Maria Laura Battagliola, Joseph Guinness</p>
                    <p>  Accurately estimating latent velocity vector fields of atmospheric winds is
crucial for understanding weather phenomena. Direct measurement of atmospheric
winds is costly, especially in the upper atmosphere, so researchers attempt to
estimate atmospheric winds by observing the movement patterns of clouds and
other features in satellite images of the atmosphere. These Derived Motion
Winds use feature tracking algorithms to search for movement within small
windows in space and time. Consequently, these algorithms cannot leverage
information from broader-scale features and cannot ensure that the collection
of wind vectors over space and time represents a physically realistic velocity
field. In this work, we use spatial-temporal Gaussian processes to model the
evolution of a scalar quantity transported over time by fluid flow. Our
framework simultaneously estimates covariance parameters and latent velocities
by maximizing the likelihood. Specifically, flows are represented using
time-dependent residual neural networks, and velocities are subsequently
derived through closed-form formulas. Performance evaluations using weather
model data demonstrate our method's accuracy and efficiency. We apply our
methods to GOES-16 images, demonstrating computational efficiency and the
ability to produce wind estimates where Derived Motion Winds fail.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.10898v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Dependency-Aware Shrinkage Priors for High Dimensional Regression</h3>
                    <p><strong>Authors:</strong> Javier Enrique Aguilar, Paul-Christian Bürkner</p>
                    <p>  In high dimensional regression, global local shrinkage priors have gained
significant traction for their ability to yield sparse estimates, improve
parameter recovery, and support accurate predictive modeling. While recent work
has explored increasingly flexible shrinkage prior structures, the role of
explicitly modeling dependencies among coefficients remains largely unexplored.
In this paper, we investigate whether incorporating such structures into
traditional shrinkage priors improves their performance. We introduce
dependency-aware shrinkage priors, an extension of continuous shrinkage priors
that integrates correlation structures inspired by Zellner's g prior approach.
We provide theoretical insights into how dependence alters the prior and
posterior structure, and evaluate the method empirically through simulations
and real data. We find that modeling dependence can improve parameter recovery
when predictors are strongly correlated, but offers only modest gains in
predictive accuracy. These findings suggest that prior dependence should be
used selectively and guided by the specific inferential goals of the analysis.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.10715v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>The Impact of Climatic Factors on Respiratory Pharmaceutical Demand: A
  Comparison of Forecasting Models for Greece</h3>
                    <p><strong>Authors:</strong> Viviana Schisa, Matteo Farnè</p>
                    <p>  Climate change is increasingly recognized as a driver of health-related
outcomes, yet its impact on pharmaceutical demand remains largely understudied.
As environmental conditions evolve and extreme weather events intensify,
anticipating their influence on medical needs is essential for designing
resilient healthcare systems.
  This study examines the relationship between climate variability and the
weekly demand for respiratory prescription pharmaceuticals in Greece, based on
a dataset spanning seven and a half years (390 weeks). Granger causality
spectra are employed to explore potential causal relationships. Following
variable selection, four forecasting models are implemented: Prophet, a Vector
Autoregressive model with exogenous variables (VARX), Random Forest with Moving
Block Bootstrap (MBB-RF), and Long Short-Term Memory (LSTM) networks.
  The MBB-RF model achieves the best performance in relative error metrics
while providing robust insights through variable importance rankings. The LSTM
model outperforms most metrics, highlighting its ability to capture nonlinear
dependencies. The VARX model, which includes Prophet-based exogenous inputs,
balances interpretability and accuracy, although it is slightly less
competitive in overall predictive performance.
  These findings underscore the added value of climate-sensitive variables in
modeling pharmaceutical demand and provide a data-driven foundation for
adaptive strategies in healthcare planning under changing environmental
conditions.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.10642v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Uncovering Drivers of EU Carbon Futures with Bayesian Networks</h3>
                    <p><strong>Authors:</strong> Jan Maciejowski, Manuele Leonelli</p>
                    <p>  The European Union Emissions Trading System (EU ETS) is a key policy tool for
reducing greenhouse gas emissions and advancing toward a net-zero economy.
Under this scheme, tradeable carbon credits, European Union Allowances (EUAs),
are issued to large emitters, who can buy and sell them on regulated markets.
We investigate the influence of financial, economic, and energy-related factors
on EUA futures prices using discrete and dynamic Bayesian networks to model
both contemporaneous and time-lagged dependencies. The analysis is based on
daily data spanning the third and fourth ETS trading phases (2013-2025),
incorporating a wide range of indicators including energy commodities, equity
indices, exchange rates, and bond markets. Results reveal that EUA pricing is
most influenced by energy commodities, especially coal and oil futures, and by
the performance of the European energy sector. Broader market sentiment,
captured through stock indices and volatility measures, affects EUA prices
indirectly via changes in energy demand. The dynamic model confirms a modest
next-day predictive influence from oil markets, while most other effects remain
contemporaneous. These insights offer regulators, institutional investors, and
firms subject to ETS compliance a clearer understanding of the interconnected
forces shaping the carbon market, supporting more effective hedging, investment
strategies, and policy design.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.10384v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>FactsR: A Safer Method for Producing High Quality Healthcare
  Documentation</h3>
                    <p><strong>Authors:</strong> Victor Petrén Bach Hansen, Lasse Krogsbøll, Jonas Lyngsø, Mathias Baltzersen, Andreas Motzfeldt, Kevin Pelgrims, Lars Maaløe</p>
                    <p>  There are now a multitude of AI-scribing solutions for healthcare promising
the utilization of large language models for ambient documentation. However,
these AI scribes still rely on one-shot, or few-shot prompts for generating
notes after the consultation has ended, employing little to no reasoning. This
risks long notes with an increase in hallucinations, misrepresentation of the
intent of the clinician, and reliance on the proofreading of the clinician to
catch errors. A dangerous combination for patient safety if vigilance is
compromised by workload and fatigue. In this paper, we introduce a method for
extracting salient clinical information in real-time alongside the healthcare
consultation, denoted Facts, and use that information recursively to generate
the final note. The FactsR method results in more accurate and concise notes by
placing the clinician-in-the-loop of note generation, while opening up new use
cases within real-time decision support.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.10360v1" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>