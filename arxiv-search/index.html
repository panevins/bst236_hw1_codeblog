<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 11/24/2025, 12:26:44 AM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>Extending the Accelerated Failure Conditionals Model to Location-Scale Families</h3>
                    <p><strong>Authors:</strong> Jared N. Lakhani</p>
                    <p>Arnold and Arvanitis (2020) introduced a novel class of bivariate conditionally specified distributions, in which dependence between two random variables is established by defining the distribution of one variable conditional on the other. This conditioning regime was formulated through survival functions and termed the accelerated failure conditionals model. Subsequently, Lakhani (2025) extended this conditioning framework to encompass distributional families whose marginal densities may exhibit unimodality and skewness, thereby moving beyond families with non-increasing densities. The present study builds on this line of work by proposing a conditional survival specification derived from a location-scale distributional family, where the dependence between $X$ and $Y$ arises not only through the acceleration function but also via a location function. An illustrative example of this new specification is developed using a Weibull marginal for $X$. The resulting models are fully characterized by closed-form expressions for their moments, and simulations are implemented using the Metropolis-Hastings algorithm. Finally, the model is applied to a dataset in which the empirical distribution of $Y$ lies on the real line, demonstrating the models' capacity to accommodate $Y$ marginals defined over $\mathbb{R}$.</p>
                    <p><a href="https://arxiv.org/pdf/2511.17463v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>On treating right-censoring events like treatments</h3>
                    <p><strong>Authors:</strong> Lan Wen, Aaron L. Sarvet, Jessica G. Young</p>
                    <p>In causal inference literature, potential outcomes are often indexed by the "elimination of all right-censoring events," leading to the perception that such a restriction is necessary for defining well-posed causal estimands. In this paper, we clarify that this restriction is not required: a well-defined estimand can be formulated without indexing on the elimination of such events. Achieving this requires a more precise classification of right-censoring events than has historically been considered, as the nature of these events has direct implications for identification of the target estimand. We provide a framework that distinguishes different types of right-censoring events from a causal perspective, and demonstrate how this framework relates to censoring definitions and assumptions in classical survival analysis literature. By bridging these perspectives, we provide a clearer understanding of how to handle right-censoring events and provide guidance for identifying causal estimands when right-censored events are present.</p>
                    <p><a href="https://arxiv.org/pdf/2511.17379v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Automobile demand forecasting: Spatiotemporal and hierarchical modeling, life cycle dynamics, and user-generated online information</h3>
                    <p><strong>Authors:</strong> Tom Nahrendorf, Stefan Minner, Helfried Binder, Richard Zinck</p>
                    <p>Premium automotive manufacturers face increasingly complex forecasting challenges due to high product variety, sparse variant-level data, and volatile market dynamics. This study addresses monthly automobile demand forecasting across a multi-product, multi-market, and multi-level hierarchy using data from a German premium manufacturer. The methodology combines point and probabilistic forecasts across strategic and operational planning levels, leveraging ensembles of LightGBM models with pooled training sets, quantile regression, and a mixed-integer linear programming reconciliation approach. Results highlight that spatiotemporal dependencies, as well as rounding bias, significantly affect forecast accuracy, underscoring the importance of integer forecasts for operational feasibility. Shapley analysis shows that short-term demand is reactive, shaped by life cycle maturity, autoregressive momentum, and operational signals, whereas medium-term demand reflects anticipatory drivers such as online engagement, planning targets, and competitive indicators, with online behavioral data considerably improving accuracy at disaggregated levels.</p>
                    <p><a href="https://arxiv.org/pdf/2511.17275v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A spatiotemporal Bayesian hierarchical model of heat-related mortality in Catalonia, Spain (2012--2022): The role of environmental and socioeconomic modifiers</h3>
                    <p><strong>Authors:</strong> David Solano, Marta Solans, Xavier Perafita, Anna Ruiz-Comellas, Marc Saez, Maria A. Barceló</p>
                    <p>Background: Extreme heat is a major public health risk, yet its relationship with mortality may be confounded or modified by air pollution and social determinants. Objectives: We aimed to quantify the effects of extreme maximum temperatures and heatwaves on daily mortality in Catalonia (2012--2022), and to assess the modifying and confounding roles of air pollutants and socioeconomic factors. Methods: We conducted a time--series ecological study across 379 basic health areas (ABS) during summer months. Mortality data from the Spanish National Statistics Institute were linked with meteorological and air pollution data. A hierarchical Bayesian spatiotemporal model, incorporating structured and unstructured random effects, was used to account for spatial and temporal dependencies, as well as observed socioeconomic confounders. Results: In total, 730,634 deaths occurred, with 216,989 in summer. Extreme heat alone was not independently associated with mortality, as its effect was fully confounded by high ozone levels and partly by socioeconomic indicators. Ozone concentrations ($\ge 120 μg/m^3$) significantly increased mortality risk, especially among individuals aged $\ge 85$ years. Greater income inequality and higher proportions of older residents also amplified vulnerability. Conclusion: Mortality risks from extreme heat in Catalonia were strongly influenced by ozone levels and social determinants. Adaptation strategies should address both compound environmental exposures together with socioeconomic vulnerability to better protect older and disadvantaged populations.</p>
                    <p><a href="https://arxiv.org/pdf/2511.17148v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>ggskewboxplots: Enhanced Boxplots for Skewed Data in R</h3>
                    <p><strong>Authors:</strong> Mustafa Cavus</p>
                    <p>Traditional boxplots are widely used for summarizing and visualizing the distribution of numerical data, yet they exhibit significant limitations when applied to skewed or heavy-tailed distributions, often leading to misclassification of outliers through swamping -- flagging typical observations as outliers -- or masking -- failing to detect true outliers. This paper addresses these limitations by systematically evaluating several alternative boxplots specifically designed to accommodate distributional asymmetry. We introduce ggskewboxplots, an R package that integrates multiple robust and skewness-aware boxplot variants, providing a unified and user-friendly framework for exploratory data analysis. Using extensive Monte Carlo simulations under controlled skewness and kurtosis conditions, implemented via the mosaic approach based on the Skewed Exponential Power distribution, we assess the sensitivity and specificity of each method. Simulation results indicate that classical Tukey-style boxplots are highly prone to swamping and masking, whereas robust skewness-adjusted variants -- particularly those leveraging quartile-based skewness measures or medcouple-based adjustments -- achieve substantially better performance. These findings offer practical guidance for selecting reliable boxplot methods in applied settings and demonstrate how the ggskewboxplots package facilitates accessible, distribution-aware visualizations within the familiar ggplot2 workflow.</p>
                    <p><a href="https://arxiv.org/pdf/2511.17091v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Flexible unimodal density estimation in hidden Markov models</h3>
                    <p><strong>Authors:</strong> Jan-Ole Koslik, Fanny Dupont, Marie Auger-Méthé, Marianne Marcoux, Nancy Heckman</p>
                    <p>1. Hidden Markov models (HMMs) are powerful tools for modelling time-series data with underlying state structure. However, selecting appropriate parametric forms for the state-dependent distributions is often challenging and can lead to model misspecification. To address this, P-spline-based nonparametric estimation of state-dependent densities has been proposed. While offering great flexibility, these approaches can result in overly complex densities (e.g. bimodal) that hinder interpretability. 2. We propose a straightforward method that builds on shape-constrained spline theory to enforce unimodality in the estimated state-dependent densities through enforcing unimodality of the spline coefficients. This constraint strikes a practical balance between model flexibility, interpretability, and parsimony. 3. Through two simulation studies and a real-world case study using narwhal (Monodon monoceros) dive data, we demonstrate the proposed approach yields more stable estimates compared to fully flexible, unconstrained models improving model performance and interpretability. 4. Our method bridges a key methodological gap, by providing a parsimonious HMM framework that balances the interpretability of parametric models with the flexibility of nonparametric estimation. This provides ecologists with a powerful tool to derive ecologically meaningful inference from telemetry data while avoiding the pitfalls of overly complex models.</p>
                    <p><a href="https://arxiv.org/pdf/2511.17071v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Effects of Distance Metrics and Scaling on the Perturbation Discrimination Score</h3>
                    <p><strong>Authors:</strong> Qiyuan Liu, Qirui Zhang, Jinhong Du, Siming Zhao, Jingshu Wang</p>
                    <p>The Perturbation Discrimination Score (PDS) is increasingly used to evaluate whether predicted perturbation effects remain distinguishable, including in Systema and the Virtual Cell Challenge. However, its behavior in high-dimensional gene-expression settings has not been examined in detail. We show that PDS is highly sensitive to the choice of similarity or distance measure and to the scale of predicted effects. Analysis of observed perturbation responses reveals that $\ell_1$ and $\ell_2$-based PDS behave very differently from cosine-based measures, even after norm matching. We provide geometric insight and discuss implications for future discrimination-based evaluation metrics.</p>
                    <p><a href="https://arxiv.org/pdf/2511.16954v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Optimising pandemic response through vaccination strategies using neural networks</h3>
                    <p><strong>Authors:</strong> Chang Zhai, Ping Chen, Zhuo Jin, David Pitt</p>
                    <p>Epidemic risk assessment poses inherent challenges, with traditional approaches often failing to balance health outcomes and economic constraints. This paper presents a data-driven decision support tool that models epidemiological dynamics and optimises vaccination strategies to control disease spread whilst minimising economic losses. The proposed economic-epidemiological framework comprises three phases: modelling, optimising, and analysing. First, a stochastic compartmental model captures epidemic dynamics. Second, an optimal control problem is formulated to derive vaccination strategies that minimise pandemic-related expenditure. Given the analytical intractability of epidemiological models, neural networks are employed to calibrate parameters and solve the high-dimensional control problem. The framework is demonstrated using COVID-19 data from Victoria, Australia, empirically deriving optimal vaccination strategies that simultaneously minimise disease incidence and governmental expenditure. By employing this three-phase framework, policymakers can adjust input values to reflect evolving transmission dynamics and continuously update strategies, thereby minimising aggregate costs, aiding future pandemic preparedness.</p>
                    <p><a href="https://arxiv.org/pdf/2511.16932v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Trust-Aware Multimodal Data Fusion for Yield Estimation: A Case Study of the 2020 Beirut Explosion</h3>
                    <p><strong>Authors:</strong> Lekha Patel, Craig Ulmer, Stephen J. Verzi, Daniel J. Krofcheck, Indu Manickam, Asmeret Naugle, Jaideep Ray</p>
                    <p>The estimation of explosive yield from heterogeneous observational data presents fundamental challenges in inverse problems, particularly when combining traditional physical measurements with modern artificial intelligence-interpreted modalities. We present a novel Bayesian fractional posterior framework that fuses seismic waves, crater dimensions, synthetic aperture radar imagery, and vision-language model interpreted ground-level images to estimate the yield of the 2020 Beirut explosion. Unlike conventional approaches that may treat data sources equally, our method learns trust weights for each modality through a Dirichlet prior, automatically calibrating the relative information content of disparate observations. Applied to the Beirut explosion, the framework yields an estimate of 0.34--0.48 kt TNT equivalent, representing 12 to 17 percent detonation efficiency relative to the 2.75 kt theoretical maximum from the blast's stored ammonium nitrate. The fractional posterior approach demonstrates superior uncertainty quantification compared to single-modality estimates while providing robustness against systematic biases. This work establishes a principled framework for integrating qualitative assessments with quantitative physical measurements, with applications to explosion monitoring, disaster response, and forensic analysis.</p>
                    <p><a href="https://arxiv.org/pdf/2511.16816v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Sensor Informativeness, Identifiability, and Uncertainty in Bayesian Inverse Problems for Structural Health Monitoring</h3>
                    <p><strong>Authors:</strong> Tammam Bakeer, Max Herbers, Steffen Marx</p>
                    <p>In Structural Health Monitoring (SHM), the recovery of distributed mechanical parameters from sparse data is often ill-posed, raising critical questions about identifiability and the reliability of inferred states. While deterministic regularization methods such as Tikhonov stabilise the inversion, they provide little insight into the spatial limits of resolution or the inherent uncertainty of the solution. This paper presents a Bayesian inverse framework that rigorously quantifies these limits, using the identification of distributed flexural rigidity from rotation (tilt) influence lines as a primary case study. Fisher information is employed as a diagnostic metric to quantify sensor informativeness, revealing how specific sensor layouts and load paths constrain the recoverable spatial features of the parameter field.
  The methodology is applied to the full-scale openLAB research bridge (TU Dresden) using data from controlled vehicle passages. Beyond estimating the flexural rigidity profile, the Bayesian formulation produces credible intervals that expose regions of practical non-identifiability, which deterministic methods may obscure. The results demonstrate that while the measurement data carry high information content for the target parameters, their utility is spatially heterogeneous and strictly bounded by the experiment design. The proposed framework unifies identification with uncertainty quantification, providing a rigorous basis for optimising sensor placement and interpreting the credibility of SHM diagnostics.</p>
                    <p><a href="https://arxiv.org/pdf/2511.16628v2" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>