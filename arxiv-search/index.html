<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 4/21/2025, 1:23:56 AM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>Word Embedding Techniques for Classification of Star Ratings</h3>
                    <p><strong>Authors:</strong> Hesham Abdelmotaleb, Craig McNeile, Malgorzata Wojtys</p>
                    <p>  Telecom services are at the core of today's societies' everyday needs. The
availability of numerous online forums and discussion platforms enables telecom
providers to improve their services by exploring the views of their customers
to learn about common issues that the customers face. Natural Language
Processing (NLP) tools can be used to process the free text collected.
  One way of working with such data is to represent text as numerical vectors
using one of many word embedding models based on neural networks. This research
uses a novel dataset of telecom customers' reviews to perform an extensive
study showing how different word embedding algorithms can affect the text
classification process. Several state-of-the-art word embedding techniques are
considered, including BERT, Word2Vec and Doc2Vec, coupled with several
classification algorithms. The important issue of feature engineering and
dimensionality reduction is addressed and several PCA-based approaches are
explored. Moreover, the energy consumption used by the different word
embeddings is investigated. The findings show that some word embedding models
can lead to consistently better text classifiers in terms of precision, recall
and F1-Score. In particular, for the more challenging classification tasks,
BERT combined with PCA stood out with the highest performance metrics.
Moreover, our proposed PCA approach of combining word vectors using the first
principal component shows clear advantages in performance over the traditional
approach of taking the average.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.13653v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>How to Achieve Higher Accuracy with Less Training Points?</h3>
                    <p><strong>Authors:</strong> Jinghan Yang, Anupam Pani, Yunchao Zhang</p>
                    <p>  In the era of large-scale model training, the extensive use of available
datasets has resulted in significant computational inefficiencies. To tackle
this issue, we explore methods for identifying informative subsets of training
data that can achieve comparable or even superior model performance. We propose
a technique based on influence functions to determine which training samples
should be included in the training set. We conducted empirical evaluations of
our method on binary classification tasks utilizing logistic regression models.
Our approach demonstrates performance comparable to that of training on the
entire dataset while using only 10% of the data. Furthermore, we found that our
method achieved even higher accuracy when trained with just 60% of the data.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.13586v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A Comparative Evaluation of a Conditional Median-Based Bayesian Growth
  Curve Modeling Approach with Missing Data</h3>
                    <p><strong>Authors:</strong> Dandan Tang, Xin Tong, Jianhui Zhou</p>
                    <p>  Longitudinal data are essential for studying within subject change and
between subject differences in change. However, missing data, especially when
the observed variables are nonnormal, remain a significant challenge in
longitudinal analysis. Full information maximum likelihood estimation (FIML)
and a two stage robust estimation (TSRE) are widely used to handle missing
data, but their effectiveness may diminish with data skewness, high missingness
rates, and nonignorable missingness. Recently, a robust median \textendash
based Bayesian (RMB) approach for growth curve modeling (GCM) was proposed to
handle nonnormal longitudinal data, yet its performance with missing data has
not been fully investigated. This study fills that gap by using Monte Carlo
simulations to evaluate RMB relative to FIML and TSRE. Overall, the RMB
\textendash based GCM is shown to be a reliable option for managing both
ignorable and nonignorable missing data across a variety of distributional
scenarios. An empirical example illustrates the application of these methods.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.13451v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Intelligent data collection for network discrimination in material flow
  analysis using Bayesian optimal experimental design</h3>
                    <p><strong>Authors:</strong> Jiankan Liao, Xun Huan, Daniel Cooper</p>
                    <p>  Material flow analyses (MFAs) are powerful tools for highlighting resource
efficiency opportunities in supply chains. MFAs are often represented as
directed graphs, with nodes denoting processes and edges representing mass
flows. However, network structure uncertainty -- uncertainty in the presence or
absence of flows between nodes -- is common and can compromise flow
predictions. While collection of more MFA data can reduce network structure
uncertainty, an intelligent data acquisition strategy is crucial to optimize
the resources (person-hours and money spent on collecting and purchasing data)
invested in constructing an MFA. In this study, we apply Bayesian optimal
experimental design (BOED), based on the Kullback-Leibler divergence, to
efficiently target high-utility MFA data -- data that minimizes network
structure uncertainty. We introduce a new method with reduced bias for
estimating expected utility, demonstrating its superior accuracy over
traditional approaches. We illustrate these advances with a case study on the
U.S. steel sector MFA, where the expected utility of collecting specific single
pieces of steel mass flow data aligns with the actual reduction in network
structure uncertainty achieved by collecting said data from the United States
Geological Survey and the World Steel Association. The results highlight that
the optimal MFA data to collect depends on the total amount of data being
gathered, making it sensitive to the scale of the data collection effort.
Overall, our methods support intelligent data acquisition strategies,
accelerating uncertainty reduction in MFAs and enhancing their utility for
impact quantification and informed decision-making.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.13382v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Deep literature reviews: an application of fine-tuned language models to
  migration research</h3>
                    <p><strong>Authors:</strong> Stefano M. Iacus, Haodong Qi, Jiyoung Han</p>
                    <p>  This paper presents a hybrid framework for literature reviews that augments
traditional bibliometric methods with large language models (LLMs). By
fine-tuning open-source LLMs, our approach enables scalable extraction of
qualitative insights from large volumes of research content, enhancing both the
breadth and depth of knowledge synthesis. To improve annotation efficiency and
consistency, we introduce an error-focused validation process in which LLMs
generate initial labels and human reviewers correct misclassifications.
Applying this framework to over 20000 scientific articles about human
migration, we demonstrate that a domain-adapted LLM can serve as a "specialist"
model - capable of accurately selecting relevant studies, detecting emerging
trends, and identifying critical research gaps. Notably, the LLM-assisted
review reveals a growing scholarly interest in climate-induced migration.
However, existing literature disproportionately centers on a narrow set of
environmental hazards (e.g., floods, droughts, sea-level rise, and land
degradation), while overlooking others that more directly affect human health
and well-being, such as air and water pollution or infectious diseases. This
imbalance highlights the need for more comprehensive research that goes beyond
physical environmental changes to examine their ecological and societal
consequences, particularly in shaping migration as an adaptive response.
Overall, our proposed framework demonstrates the potential of fine-tuned LLMs
to conduct more efficient, consistent, and insightful literature reviews across
disciplines, ultimately accelerating knowledge synthesis and scientific
discovery.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.13685v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Anemia, weight, and height among children under five in Peru from 2007
  to 2022: A Panel Data analysis</h3>
                    <p><strong>Authors:</strong> Luis-Felipe Arizmendi, Carlos De la Torre-Domingo, Erick W. Rengifo</p>
                    <p>  Econometrics in general, and Panel Data methods in particular, are becoming
crucial in Public Health Economics and Social Policy analysis. In this
discussion paper, we employ a helpful approach of Feasible Generalized Least
Squares (FGLS) to assess if there are statistically relevant relationships
between hemoglobin (adjusted to sea-level), weight, and height from 2007 to
2022 in children up to five years of age in Peru. By using this method, we may
find a tool that allows us to confirm if the relationships considered between
the target variables by the Peruvian agencies and authorities are in the right
direction to fight against chronic malnutrition and stunting.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.12888v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Spatial Functional Deep Neural Network Model: A New Prediction Algorithm</h3>
                    <p><strong>Authors:</strong> Merve Basaran, Ufuk Beyaztas, Han Lin Shang, Zaher Mundher Yaseen</p>
                    <p>  Accurate prediction of spatially dependent functional data is critical for
various engineering and scientific applications. In this study, a spatial
functional deep neural network model was developed with a novel non-linear
modeling framework that seamlessly integrates spatial dependencies and
functional predictors using deep learning techniques. The proposed model
extends classical scalar-on-function regression by incorporating a spatial
autoregressive component while leveraging functional deep neural networks to
capture complex non-linear relationships. To ensure a robust estimation, the
methodology employs an adaptive estimation approach, where the spatial
dependence parameter was first inferred via maximum likelihood estimation,
followed by non-linear functional regression using deep learning. The
effectiveness of the proposed model was evaluated through extensive Monte Carlo
simulations and an application to Brazilian COVID-19 data, where the goal was
to predict the average daily number of deaths. Comparative analysis with
maximum likelihood-based spatial functional linear regression and functional
deep neural network models demonstrates that the proposed algorithm
significantly improves predictive performance. The results for the Brazilian
COVID-19 data showed that while all models achieved similar mean squared error
values over the training modeling phase, the proposed model achieved the lowest
mean squared prediction error in the testing phase, indicating superior
generalization ability.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.12750v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Bayesian Density-Density Regression with Application to Cell-Cell
  Communications</h3>
                    <p><strong>Authors:</strong> Khai Nguyen, Yang Ni, Peter Mueller</p>
                    <p>  We introduce a scalable framework for regressing multivariate distributions
onto multivariate distributions, motivated by the application of inferring
cell-cell communication from population-scale single-cell data. The observed
data consist of pairs of multivariate distributions for ligands from one cell
type and corresponding receptors from another. For each ordered pair $e=(l,r)$
of cell types $(l \neq r)$ and each sample $i = 1, \ldots, n$, we observe a
pair of distributions $(F_{ei}, G_{ei})$ of gene expressions for ligands and
receptors of cell types $l$ and $r$, respectively. The aim is to set up a
regression of receptor distributions $G_{ei}$ given ligand distributions
$F_{ei}$. A key challenge is that these distributions reside in distinct spaces
of differing dimensions. We formulate the regression of multivariate densities
on multivariate densities using a generalized Bayes framework with the sliced
Wasserstein distance between fitted and observed distributions. Finally, we use
inference under such regressions to define a directed graph for cell-cell
communications.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.12617v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Bias in studies of prenatal exposures using real-world data due to
  pregnancy identification method</h3>
                    <p><strong>Authors:</strong> Chase D. Latour, Jessie K. Edwards, Michele Jonsson Funk, Elizabeth A. Suarez, Kim Boggess, Mollie E. Wood</p>
                    <p>  Background: Researchers typically identify pregnancies in healthcare data
based on observed outcomes (e.g., delivery). This outcome-based approach misses
pregnancies that received prenatal care but whose outcomes were not recorded
(e.g., at-home miscarriage), potentially inducing selection bias in effect
estimates for prenatal exposures. Alternatively, prenatal encounters can be
used to identify pregnancies, including those with unobserved outcomes.
However, this prenatal approach requires methods to address missing data.
Methods: We simulated 10,000,000 pregnancies and estimated the total effect of
initiating treatment on the risk of preeclampsia. We generated data for 36
scenarios in which we varied the effect of treatment on miscarriage and/or
preeclampsia; the percentage with missing outcomes (5% or 20%); and the cause
of missingness: (1) measured covariates, (2) unobserved miscarriage, and (3) a
mix of both. We then created three analytic samples to address missing
pregnancy outcomes: observed deliveries, observed deliveries and miscarriages,
and all pregnancies. Treatment effects were estimated using non-parametric
direct standardization. Results: Risk differences (RDs) and risk ratios (RRs)
from the three analytic samples were similarly biased when all missingness was
due to unobserved miscarriage (log-transformed RR bias range: -0.12-0.33 among
observed deliveries; -0.11-0.32 among observed deliveries and miscarriages; and
-0.11-0.32 among all pregnancies). When predictors of missingness were
measured, only the all pregnancies approach was unbiased (-0.27-0.33;
-0.29-0.03; and -0.02-0.01, respectively). Conclusions: When all missingness
was due to miscarriage, the analytic samples returned similar effect estimates.
Only among all pregnancies did bias decrease as the proportion of missingness
due to measured variables increased.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.12415v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Trend Filtered Mixture of Experts for Automated Gating of High-Frequency
  Flow Cytometry Data</h3>
                    <p><strong>Authors:</strong> Sangwon Hyun, Tim Coleman, Francois Ribalet, Jacob Bien</p>
                    <p>  Ocean microbes are critical to both ocean ecosystems and the global climate.
Flow cytometry, which measures cell optical properties in fluid samples, is
routinely used in oceanographic research. Despite decades of accumulated data,
identifying key microbial populations (a process known as ``gating'') remains a
significant analytical challenge. To address this, we focus on gating
multidimensional, high-frequency flow cytometry data collected {\it
continuously} on board oceanographic research vessels, capturing time- and
space-wise variations in the dynamic ocean. Our paper proposes a novel
mixture-of-experts model in which both the gating function and the experts are
given by trend filtering. The model leverages two key assumptions: (1) Each
snapshot of flow cytometry data is a mixture of multivariate Gaussians and (2)
the parameters of these Gaussians vary smoothly over time. Our method uses
regularization and a constraint to ensure smoothness and that cluster means
match biologically distinct microbe types. We demonstrate, using flow cytometry
data from the North Pacific Ocean, that our proposed model accurately matches
human-annotated gating and corrects significant errors.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.12287v1" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>