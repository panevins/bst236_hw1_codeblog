<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 1/19/2026, 12:35:40 AM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>Study on Light Propagation through Space-Time Random Media via Stochastic Partial Differential Equations</h3>
                    <p><strong>Authors:</strong> Chaoran Wang, Jinquan Qi, Shuang Liu, Chenjin Deng, Shensheng Han</p>
                    <p>In this letter, the theory of stochastic partial differential equations is applied to the propagation of light fields in space-time random media. By modeling the fluctuation of refractive index's square of the media as a random field, we demonstrate that the hyperbolic Anderson model is applicable to describing the propagation of light fields in such media. Additionally, several new quantitative characterizations of the stochastic properties that govern the light fields are derived. Furthermore, the validity of the theoretical framework and corresponding results is experimentally verified by analyzing the statistical properties of the propagated light fields after determining the spatial and temporal stochastic features of the random media. The results presented here provide a more accurate theoretical basis for better understanding random phenomena in emerging domains such as free-space optical communication, detection, and imaging in transparent random media. The study could also have practical guiding significance for experimental system design in these fields.</p>
                    <p><a href="https://arxiv.org/pdf/2601.11213v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Distributional Treatment Effects of Content Promotion: Evidence from an ABEMA Field Experiment</h3>
                    <p><strong>Authors:</strong> Shota Yasui, Tatsushi Oka, Undral Byambadalai, Yuki Oishi</p>
                    <p>We examine the impact of top-of-screen promotions on viewing time at ABEMA, a leading video streaming platform in Japan. To this end, we conduct a large-scale randomized controlled trial. Given the non-standard distribution of user viewing times, we estimate distributional treatment effects. Our estimation results document that spotlighting content through these promotions effectively boosts user engagement across diverse content types. Notably, promoting short content proves most effective in that it not only retains users but also motivates them to watch subsequent episodes.</p>
                    <p><a href="https://arxiv.org/pdf/2601.11185v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Analyzing Residential Speeding Using Connected Vehicle Data: A Case Study in Charlottesville, VA Area</h3>
                    <p><strong>Authors:</strong> Shi Feng, B. Brian Park, Andrew Mondschein</p>
                    <p>This study uses connected vehicle data to analyze speeding behavior on residential roads. A scalable pipeline processes trajectory data and supplements missing speed limits to generate summaries at OpenStreetMap's way ID level. The findings reveal a highly skewed distribution of both aggressive and reckless speeding. Based on a case study of Charlottesville, VA's connected vehicle data on residential roads, we found that 38% of segments had at least one instance of aggressive speeding, and 20% had at least one instance of reckless speeding. In addition, night time speeding is 27 times more prevalent than day time, and extreme violations on specific road segments highlight how severe the issue can be. Several segments rank among the top 10 for both aggressive and reckless speedings, indicating that there exist high-risk residential roads. These findings support the need for both spatial and behavioral interventions. The analysis provides a rich foundation for policy and planning, offering a valuable complement to traditional enforcement and planning tools. In conclusion, this framework sets the foundation for future applications in traffic safety analytics, demonstrating the growing potential of telematics data to inform safer, more livable communities.</p>
                    <p><a href="https://arxiv.org/pdf/2601.10974v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A Note on Harmonic Underspecification in Log-Normal Trigonometric Regression</h3>
                    <p><strong>Authors:</strong> Michael T. Gorczyca</p>
                    <p>Analysis of biological rhythm data often involves performing least squares trigonometric regression, which models the oscillations of a response over time as a sum of sinusoidal components. When the response is not normally distributed, an investigator will either transform the response before applying least squares trigonometric regression or extend trigonometric regression to a generalized linear model (GLM) framework. In this note, we compare these two approaches when the number of oscillation harmonics is underspecified. We assume data are sampled under an equispaced experimental design and that a log link function would be appropriate for a GLM. We show that when the response follows a generalized gamma distribution, least squares trigonometric regression with a log-transformed response, or log-normal trigonometric regression, produces unbiased parameter estimates for the oscillation harmonics, even when the number of oscillation harmonics is underspecified. In contrast, GLMs require correct specification to produce unbiased parameter estimates. We apply both methods to cortisol level data and find that only log-normal trigonometric regression produces parameter estimates that are invariant to the number of specified oscillation harmonics. Additionally, when a sufficiently large number of oscillation harmonics is specified, both methods produce identical parameter estimates for the oscillation harmonics.</p>
                    <p><a href="https://arxiv.org/pdf/2601.10919v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Optimal and Unbiased Fluxes from Up-the-Ramp Detectors under Variable Illumination</h3>
                    <p><strong>Authors:</strong> Bowen Li, Kevin A. McKinnon, Andrew K. Saydjari, Conor Sayres, Gwendolyn M. Eadie, Andrew R. Casey, Jon A. Holtzman, Timothy D. Brandt, Jose G. Fernandez-Trincado</p>
                    <p>Near-infrared (NIR) detectors -- which use non-destructive readouts to measure time-series counts-per-pixel -- play a crucial role in modern astrophysics. Standard NIR flux extraction techniques were developed for space-based observations and assume that source fluxes are constant over an observation. However, ground-based telescopes often see short-timescale atmospheric variations that can dramatically change the number of photons arriving at a pixel. This work presents a new statistical model that shares information between neighboring spectral pixels to characterize time-variable observations and extract unbiased fluxes with optimal uncertainties. We generate realistic synthetic data using a variety of flux and amplitude-of-time-variability conditions to confirm that our model recovers unbiased and optimal estimates of both the true flux and the time-variable signal. We find that the time-variable model should be favored over a constant-flux model when the observed count rates change by more than 3.5%. Ignoring time variability in the data can result in flux-dependent, unknown-sign biases that are as large as ~120% of the flux uncertainty. Using real APOGEE spectra, we find empirical evidence for approximately wavelength-independent, time-dependent variations in count rates with amplitudes much greater than the 3.5% threshold. Our model can robustly measure and remove the time-dependence in real data, improving the quality of data-model comparison. We show several examples where the observed time-dependence quantitatively agrees with independent measurements of observing conditions, such as variable cloud cover and seeing.</p>
                    <p><a href="https://arxiv.org/pdf/2601.10878v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Locally sparse varying coefficient mixed model with application to longitudinal microbiome differential abundance</h3>
                    <p><strong>Authors:</strong> Simon Fontaine, Nisha J. D'Silva, Marcell Costa de Medeiros, Grace Y. Chen, Ji Zhu, Gen Li</p>
                    <p>Differential abundance (DA) analysis in microbiome studies has recently been used to uncover a plethora of associations between microbial composition and various health conditions. While current approaches to DA typically apply only to cross-sectional data, many studies feature a longitudinal design to better understand the underlying microbial dynamics. To study DA in longitudinal microbial studies, we introduce a novel varying coefficient mixed-effects model with local sparsity. The proposed method can identify time intervals of significant group differences while accounting for temporal dependence. Specifically, we exploit a penalized kernel smoothing approach for parameter estimation and include a random effect to account for serial correlation. In particular, our method operates effectively regardless of whether sampling times are shared across subjects, accommodating irregular sampling and missing observations. Simulation studies demonstrate the necessity of modeling dependence for precise estimation and support recovery. The application of our method to a longitudinal study of mice oral microbiome during cancer development revealed significant scientific insights that were otherwise not discernible through cross-sectional analyses. An R implementation is available at https://github.com/fontaine618/LSVCMM.</p>
                    <p><a href="https://arxiv.org/pdf/2601.10872v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Beyond Unidimensionality: General Factors and Residual Heterogeneity in Performance Evaluation</h3>
                    <p><strong>Authors:</strong> Krishna Sharma, Pritam Basnet</p>
                    <p>How do evaluation systems compress multidimensional performance information into summary ratings? Using expert assessments of 9,669 professional soccer players on 28 attributes, we characterize the dimensional structure of evaluation outputs. The first principal component explains 40.6% of attribute variance, indicating a strong general factor, but formal noise discrimination procedures retain four components and bootstrap resampling confirms that this structure is highly stable. Internal consistency is high without evidence of redundancy. In out of sample prediction of expert overall ratings, a comprehensive model using the full attribute set substantially outperforms a single-factor summary (cross-validated R squared = 0.814). Overall, performance evaluations exhibit moderate information compression; they combine shared variance with stable residual dimensions that are economically meaningful for evaluation outcomes, with direct implications for the design of measurement systems.</p>
                    <p><a href="https://arxiv.org/pdf/2601.10862v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>A Bayesian Discrete Framework for Enhancing Decision-Making Processes in Clinical Trial Designs and Evaluations</h3>
                    <p><strong>Authors:</strong> Paramahansa Pramanik, Arnab Kumar Maity, Anjan Mandal, Haley Kate Robinson</p>
                    <p>This study examines the application of Bayesian approach in the context of clinical trials, emphasizing their increasing importance in contemporary biomedical research. While conventional frequentist approach provides a foundational basis for analysis, it often lacks the flexibility to integrate prior knowledge, which can constrain its effectiveness in adaptive settings. In contrast, Bayesian methods enable continual refinement of statistical inferences through the assimilation of accumulating evidence, thereby supporting more informed decision-making and improving the reliability of trial findings. This paper also considers persistent challenges in clinical investigations, including replication difficulties and the misinterpretation of statistical results, suggesting that Bayesian strategies may offer a path toward enhanced analytical robustness. Moreover, discrete probability models, specifically the Binomial, Poisson, and Negative Binomial distributions are explored for their suitability in modeling clinical endpoints, particularly in trials involving binary responses or data with overdispersion. The discussion further incorporates Bayesian networks and Bayesian estimation techniques, with a comparative evaluation against maximum likelihood estimation to elucidate differences in inferential behavior and practical implementation.</p>
                    <p><a href="https://arxiv.org/pdf/2601.10615v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>MitoFREQ: A Novel Approach for Mitogenome Frequency Estimation from Top-level Haplogroups and Single Nucleotide Variants</h3>
                    <p><strong>Authors:</strong> Mikkel Meyer Andersen, Nicole Huber, Kimberly S Andreaggi, TÃ³ra Oluffa Stenberg Olsen, Walther Parson, Charla Marshall</p>
                    <p>Lineage marker population frequencies can serve as one way to express evidential value in forensic genetics. However, for high-quality whole mitochondrial DNA genome sequences (mitogenomes), population data remain limited. In this paper, we offer a new method, MitoFREQ, for estimating the population frequencies of mitogenomes. MitoFREQ uses the mitogenome resources HelixMTdb and gnomAD, harbouring information from 195,983 and 56,406 mitogenomes, respectively. Neither HelixMTdb nor gnomAD can be queried directly for individual mitogenome frequencies, but offers single nucleotide variant (SNV) allele frequencies for each of 30 "top-level" haplogroups (TLHG). We propose using the HelixMTdb and gnomAD resources by classifying a given mitogenome within the TLHG scheme and subsequently using the frequency of its rarest SNV within that TLHG weighted by the TLHG frequency. We show that this method is guaranteed to provide a higher population frequency estimate than if a refined haplogroup and its SNV frequencies were used. Further, we show that top-level haplogrouping can be achieved by using only 227 specific positions for 99.9% of the tested mitogenomes, potentially making the method available for low-quality samples. The method was tested on two types of datasets: high-quality forensic reference datasets and a diverse collection of scrutinised mitogenomes from GenBank. This dual evaluation demonstrated that the approach is robust across both curated forensic data and broader population-level sequences. This method produced likelihood ratios in the range of 100-100,000, demonstrating its potential to strengthen the statistical evaluation of forensic mtDNA evidence. We have developed an open-source R package `mitofreq` that implements our method, including a Shiny app where custom TLHG frequencies can be supplied.</p>
                    <p><a href="https://arxiv.org/pdf/2601.10464v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Modeling mental health trajectories during the COVID-19 pandemic using UK-wide data in the presence of sociodemographic variables</h3>
                    <p><strong>Authors:</strong> Glenna Nightingale, Karthik Mohan, Eloi Ribe, Valentin Popov, Shakes Wang, Clara Calia, Luciana Brondi, Sohan Seth</p>
                    <p>Background: The negative effects of the COVID-19 pandemic on the mental health and well-being of populations are an important public health issue. Our study aims to determine the underlying factors shaping mental health trajectories during the COVID-19 pandemic in the UK. Methods: Data from the Understanding Society COVID-19 Study were utilized and the core analysis focussed on GHQ36 scores as the outcome variable. We used GAMs to evaluate trends over time and the role of sociodemographic variables, i.e., age, sex, ethnicity, country of residence (in UK), job status (employment), household income, living with a partner, living with children under age 16, and living with a long-term illness, on the variation of mental health during the study period. Results: Statistically significant differences in mental health were observed for age, sex,ethnicity, country of residence (in UK), job status (employment), household income, living with a partner, living with children under age 16, and living with a long-term illness. Women experienced higher GHQ36 scores relative to men with the GHQ36 score expected to increase by 1.260 (95%CI: 1.176, 1.345). Individuals living without a partner were expected to have higher GHQ36 scores, of 1.050 (95%CI: 0.949, 1.148) more than those living with a partner, and age groups 16-34, 35-44, 45-54, 55-64 experienced higher GHQ36 scores relative to those who were 65+. Individuals with relatively lower household income were likely to have poorer mental health relative to those who were more well off. Conclusion: This study identifies key demographic determinants shaping mental health trajectories during the COVID-19 pandemic in the UK. Policies aiming to reduce mental health inequalities should target women, youth, individuals living without a partner, individuals living with children under 16, individuals with a long-term illness, and lower income families.</p>
                    <p><a href="https://arxiv.org/pdf/2601.10445v1" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>