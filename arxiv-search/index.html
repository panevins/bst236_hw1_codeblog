<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 5/5/2025, 1:24:45 AM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>Integration of Multi-Mode Preference into Home Energy Management System
  Using Deep Reinforcement Learning</h3>
                    <p><strong>Authors:</strong> Mohammed Sumayli, Olugbenga Moses Anubi</p>
                    <p>  Home Energy Management Systems (HEMS) have emerged as a pivotal tool in the
smart home ecosystem, aiming to enhance energy efficiency, reduce costs, and
improve user comfort. By enabling intelligent control and optimization of
household energy consumption, HEMS plays a significant role in bridging the gap
between consumer needs and energy utility objectives. However, much of the
existing literature construes consumer comfort as a mere deviation from the
standard appliance settings. Such deviations are typically incorporated into
optimization objectives via static weighting factors. These factors often
overlook the dynamic nature of consumer behaviors and preferences. Addressing
this oversight, our paper introduces a multi-mode Deep Reinforcement
Learning-based HEMS (DRL-HEMS) framework, meticulously designed to optimize
based on dynamic, consumer-defined preferences. Our primary goal is to augment
consumer involvement in Demand Response (DR) programs by embedding dynamic
multi-mode preferences tailored to individual appliances. In this study, we
leverage a model-free, single-agent DRL algorithm to deliver a HEMS framework
that is not only dynamic but also user-friendly. To validate its efficacy, we
employed real-world data at 15-minute intervals, including metrics such as
electricity price, ambient temperature, and appliances' power consumption. Our
results show that the model performs exceptionally well in optimizing energy
consumption within different preference modes. Furthermore, when compared to
traditional algorithms based on Mixed-Integer Linear Programming (MILP), our
model achieves nearly optimal performance while outperforming in computational
efficiency.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.01332v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Geoinformation dependencies in geographic space and beyond</h3>
                    <p><strong>Authors:</strong> Jon Wang, Meng Lu</p>
                    <p>  The use of geospatially dependent information, which has been stipulated as a
law in geography, to model geographic patterns forms the cornerstone of
geostatistics, and has been inherited in many data science based techniques as
well, such as statistical learning algorithms. Still, we observe hesitations in
interpreting geographic dependency scientifically as a property in geography,
since interpretations of such dependency are subject to model choice with
different hypotheses of trends and stationarity. Rather than questioning what
can be considered as trends or why it is non-stationary, in this work, we share
and consolidate a view that the properties of geographic dependency, being it
trending or stationary, are essentially variations can be explained further by
unobserved or unknown predictors, and not intrinsic to geographic space.
Particularly, geoinformation dependency properties are in fact a projection of
high dimensional feature space formed by all potential predictors into the
lower dimension of geographic space, where geographic coordinates are
equivalent to other predictors for modelling geographic patterns. This work
brings together different aspects of geographic dependency, including
similarity and heterogeneity, under a coherent framework, and aligns with the
understanding of modelling in high dimensional feature space with different
modelling concept including the classical geostatistics, Gaussian Process
Regression and popular data science based spatial modelling techniques.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.01260v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Joint Modelling of Line and Point Data on Metric Graphs</h3>
                    <p><strong>Authors:</strong> Karina Lilleborge, Sara Martino, Geir-Arne Fuglstad, Finn Lindgren, Rikke Ingebrigtsen</p>
                    <p>  Metric graphs are useful tools for describing spatial domains like road and
river networks, where spatial dependence act along the network. We take
advantage of recent developments for such Gaussian Random Fields (GRFs), and
consider joint spatial modelling of observations with different spatial
supports. Motivated by an application to traffic state modelling in Trondheim,
Norway, we consider line-referenced data, which can be described by an integral
of the GRF along a line segment on the metric graph, and point-referenced data.
Through a simulation study inspired by the application, we investigate the
number of replicates that are needed to estimate parameters and to predict
unobserved locations. The former is assessed using bias and variability, and
the latter is assessed through root mean square error (RMSE), continuous rank
probability scores (CRPSs), and coverage. Joint modelling is contrasted with a
simplified approach that treat line-referenced observations as point-referenced
observations. The results suggest joint modelling leads to strong improvements.
The application to Trondheim, Norway, combines point-referenced induction loop
data and line-referenced public transportation data. To ensure positive speeds,
we use a non-linear link function, which requires integrals of non-linear
combinations of the linear predictor. This is made computationally feasible by
a combination of the R packages inlabru and MetricGraph, and new code for
processing geographical line data to work with existing graph representations
and fmesher methods for dealing with line support in inlabru on objects from
MetricGraph. We fit the model to two datasets where we expect different spatial
dependency and compare the results.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.01175v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Low-rank bilinear autoregressive models for three-way criminal activity
  tensors</h3>
                    <p><strong>Authors:</strong> Gregor Zens, Carlos DÃ­az, Daniele Durante, Eleonora Patacchini</p>
                    <p>  Criminal activity data are typically available via a three-way tensor
encoding the reported frequencies of different crime categories across time and
space. The challenges that arise in the design of interpretable, yet realistic,
model-based representations of the complex dependencies within and across these
three dimensions have led to an increasing adoption of black-box predictive
strategies. Although this perspective has proved successful in producing
accurate forecasts guiding targeted interventions, the lack of interpretable
model-based characterizations of the dependence structures underlying criminal
activity tensors prevents from inferring the cascading effects of these
interventions across the different dimensions. We address this gap through the
design of a low-rank bilinear autoregressive model which achieves comparable
predictive performance to black-box strategies, while allowing interpretable
inference on the dependence structures of criminal activity reports across
crime categories, time, and space. This representation incorporates the time
dimension via an autoregressive construction, accounting for spatial effects
and dependencies among crime categories through a separable low-rank bilinear
formulation. When applied to Chicago police reports, the proposed model
showcases remarkable predictive performance and also reveals interpretable
dependence structures unveiling fundamental crime dynamics. These results
facilitate the design of more refined intervention policies informed by
cascading effects of the policy itself.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.01166v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Towards modelling lifetime default risk: Exploring different subtypes of
  recurrent event Cox-regression models</h3>
                    <p><strong>Authors:</strong> Arno Botha, Tanja Verster, Bernard Scheepers</p>
                    <p>  In the pursuit of modelling a loan's probability of default (PD) over its
lifetime, repeat default events are often ignored when using Cox Proportional
Hazard (PH) models. Excluding such events may produce biased and inaccurate
PD-estimates, which can compromise financial buffers against future losses.
Accordingly, we investigate a few subtypes of Cox-models that can incorporate
recurrent default events. Using South African mortgage data, we explore both
the Andersen-Gill (AG) and the Prentice-Williams-Peterson (PWP) spell-time
models. These models are compared against a baseline that deliberately ignores
recurrent events, called the time to first default (TFD) model. Models are
evaluated using Harrell's c-statistic, adjusted Cox-Sell residuals, and a novel
extension of time-dependent receiver operating characteristic (ROC) analysis.
From these Cox-models, we demonstrate how to derive a portfolio-level
term-structure of default risk, which is a series of marginal PD-estimates at
each point of the average loan's lifetime. While the TFD- and PWP-models do not
differ significantly across all diagnostics, the AG-model underperformed
expectations. Depending on the prevalence of recurrent defaults, one may
therefore safely ignore them when estimating lifetime default risk.
Accordingly, our work enhances the current practice of using Cox-modelling in
producing timeous and accurate PD-estimates under IFRS 9.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.01044v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Drilling into Erasmus learning mobility flows between countries
  2014-2024</h3>
                    <p><strong>Authors:</strong> Vladimir Batagelj</p>
                    <p>  Analyzing the Erasmus mobility network, we illustrate typical problems and
approaches in analyzing weighted networks. We propose alternative exploratory
views on the network "Erasmus+ learning mobility flows since 2014". The network
has 35 nodes (countries), is very dense, and the range of link weights (number
of visits) is huge (from 1 to 217003). An increasing transformation is used to
reduce the range. The traditional graph-based visualization is unreadable. To
gain insight into the structure of a dense network, it can be reduced to a
skeleton by removing less essential links and/or nodes. We have determined the
1-neighbors and 2-neighbors subnetworks. The 1-neighbors skeleton highlights
Spain as the main attractor in the network. The 2-neighbors skeleton shows the
dominant role of Spain, Germany, France, and Italy. The hubs and authorities,
Pathfinder and Ps cores methods confirm these observations.
  Using the "right" order of the nodes in a matrix representation can reveal
the network structure as block patterns in the displayed matrix. The clustering
of network nodes based on corrected Salton dissimilarity again shows the
dominant role of Spain, Germany, France, and Italy, but also two main clusters
of the division into developed/less developed countries. The Balassa
normalization (log(measured/expected) visits) matrix shows that most visits
within the two main clusters are above expected, while most visits between them
are below expected; within the clusters of Balkan countries, Baltic countries,
{SK, CZ, HU}, {IS, DK, NO} visits are much above expected, etc.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.00889v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Multi-site modelling and reconstruction of past extreme skew surges
  along the French Atlantic coast</h3>
                    <p><strong>Authors:</strong> Nathan Huet, Philippe Naveau, Anne Sabourin</p>
                    <p>  Appropriate modelling of extreme skew surges is crucial, particularly for
coastal risk management. Our study focuses on modelling extreme skew surges
along the French Atlantic coast, with a particular emphasis on investigating
the extremal dependence structure between stations. We employ the
peak-over-threshold framework, where a multivariate extreme event is defined
whenever at least one location records a large value, though not necessarily
all stations simultaneously. A novel method for determining an appropriate
level (threshold) above which observations can be classified as extreme is
proposed. Two complementary approaches are explored. First, the multivariate
generalized Pareto distribution is employed to model extremes, leveraging its
properties to derive a generative model that predicts extreme skew surges at
one station based on observed extremes at nearby stations. Second, a novel
extreme regression framework is assessed for point predictions. This specific
regression framework enables accurate point predictions using only the "angle"
of input variables, i.e. input variables divided by their norms. The ultimate
objective is to reconstruct historical skew surge time series at stations with
limited data. This is achieved by integrating extreme skew surge data from
stations with longer records, such as Brest and Saint-Nazaire, which provide
over 150 years of observations.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.00835v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>On the Mechanistic Interpretability of Neural Networks for Causality in
  Bio-statistics</h3>
                    <p><strong>Authors:</strong> Jean-Baptiste A. Conan</p>
                    <p>  Interpretable insights from predictive models remain critical in
bio-statistics, particularly when assessing causality, where classical
statistical and machine learning methods often provide inherent clarity. While
Neural Networks (NNs) offer powerful capabilities for modeling complex
biological data, their traditional "black-box" nature presents challenges for
validation and trust in high-stakes health applications. Recent advances in
Mechanistic Interpretability (MI) aim to decipher the internal computations
learned by these networks. This work investigates the application of MI
techniques to NNs within the context of causal inference for bio-statistics.
  We demonstrate that MI tools can be leveraged to: (1) probe and validate the
internal representations learned by NNs, such as those estimating nuisance
functions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)
discover and visualize the distinct computational pathways employed by the
network to process different types of inputs, potentially revealing how
confounders and treatments are handled; and (3) provide methodologies for
comparing the learned mechanisms and extracted insights across statistical,
machine learning, and NN models, fostering a deeper understanding of their
respective strengths and weaknesses for causal bio-statistical analysis.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.00555v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Ireland Topsoil Contamination Analysis: A Clustering Approach</h3>
                    <p><strong>Authors:</strong> Mimi Zhang</p>
                    <p>  This study investigates topsoil contamination in Ireland using geochemical
data from the Tellus Programme, analyzing 4,278 soil samples across 17,983
square kilometer. The research employs CPF clustering with spatial constraints
to classify samples into seven different groups, revealing distinct
contamination patterns.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.00510v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Spatial vertical regression for spatial panel data: Evaluating the
  effect of the Florentine tramway's first line on commercial vitality</h3>
                    <p><strong>Authors:</strong> Giulio Grossi, Alessandra Mattei, Georgia Papadogeorgou</p>
                    <p>  Synthetic control methods are commonly used in panel data settings to
evaluate the effect of an intervention. In many of these cases, the treated and
control units correspond to spatial units such as regions or neighborhoods. Our
approach addresses the challenge of understanding how an intervention applied
at specific locations influences the surrounding area. Traditional synthetic
control applications may struggle with defining the effective area of impact,
the extent of treatment propagation across space, and the variation of effects
with distance from the treatment sites. To address these challenges, we
introduce Spatial Vertical Regression (SVR) within the Bayesian paradigm. This
innovative approach allows us to accurately predict the outcomes in varying
proximities to the treatment sites, while meticulously accounting for the
spatial structure inherent in the data. Specifically, rooted on the vertical
regression framework of the synthetic control method, SVR employs a Gaussian
process to ensure that the imputation of missing potential outcomes for areas
of different distance around the treatment sites is spatially coherent,
reflecting the expectation that nearby areas experience similar outcomes and
have similar relationships to control areas. This approach is particularly
pertinent to our study on the Florentine tramway's first line construction. We
study its influence on the local commercial landscape, focusing on how business
prevalence varies at different distances from the tram stops.
</p>
                    <p><a href="http://arxiv.org/pdf/2505.00450v1" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>