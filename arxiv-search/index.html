<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 2/19/2025, 12:08:43 AM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>Performance Evaluation of Large Language Models in Statistical
  Programming</h3>
                    <p><strong>Authors:</strong> Xinyi Song, Kexin Xie, Lina Lee, Ruizhe Chen, Jared M. Clark, Hao He, Haoran He, Jie Min, Xinlei Zhang, Simin Zheng, Zhiyang Zhang, Xinwei Deng, Yili Hong</p>
                    <p>  The programming capabilities of large language models (LLMs) have
revolutionized automatic code generation and opened new avenues for automatic
statistical analysis. However, the validity and quality of these generated
codes need to be systematically evaluated before they can be widely adopted.
Despite their growing prominence, a comprehensive evaluation of statistical
code generated by LLMs remains scarce in the literature. In this paper, we
assess the performance of LLMs, including two versions of ChatGPT and one
version of Llama, in the domain of SAS programming for statistical analysis.
Our study utilizes a set of statistical analysis tasks encompassing diverse
statistical topics and datasets. Each task includes a problem description,
dataset information, and human-verified SAS code. We conduct a comprehensive
assessment of the quality of SAS code generated by LLMs through human expert
evaluation based on correctness, effectiveness, readability, executability, and
the accuracy of output results. The analysis of rating scores reveals that
while LLMs demonstrate usefulness in generating syntactically correct code,
they struggle with tasks requiring deep domain understanding and may produce
redundant or incorrect results. This study offers valuable insights into the
capabilities and limitations of LLMs in statistical programming, providing
guidance for future advancements in AI-assisted coding systems for statistical
analysis.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.13117v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Bridging the Data Gap in AI Reliability Research and Establishing
  DR-AIR, a Comprehensive Data Repository for AI Reliability</h3>
                    <p><strong>Authors:</strong> Simin Zheng, Jared M. Clark, Fatemeh Salboukh, Priscila Silva, Karen da Mata, Fenglian Pan, Jie Min, Jiayi Lian, Caleb B. King, Lance Fiondella, Jian Liu, Xinwei Deng, Yili Hong</p>
                    <p>  Artificial intelligence (AI) technology and systems have been advancing
rapidly. However, ensuring the reliability of these systems is crucial for
fostering public confidence in their use. This necessitates the modeling and
analysis of reliability data specific to AI systems. A major challenge in AI
reliability research, particularly for those in academia, is the lack of
readily available AI reliability data. To address this gap, this paper focuses
on conducting a comprehensive review of available AI reliability data and
establishing DR-AIR: a data repository for AI reliability. Specifically, we
introduce key measurements and data types for assessing AI reliability, along
with the methodologies used to collect these data. We also provide a detailed
description of the currently available datasets with illustrative examples.
Furthermore, we outline the setup of the DR-AIR repository and demonstrate its
practical applications. This repository provides easy access to datasets
specifically curated for AI reliability research. We believe these efforts will
significantly benefit the AI research community by facilitating access to
valuable reliability data and promoting collaboration across various academic
domains within AI. We conclude our paper with a call to action, encouraging the
research community to contribute and share AI reliability data to further
advance this critical field of study.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12386v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Locally-Deployed Chain-of-Thought (CoT) Reasoning Model in Chemical
  Engineering: Starting from 30 Experimental Data</h3>
                    <p><strong>Authors:</strong> Tianhang Zhou, Yingchun Niu, Xingying Lan, Chunming Xu</p>
                    <p>  In the field of chemical engineering, traditional data-processing and
prediction methods face significant challenges. Machine-learning and
large-language models (LLMs) also have their respective limitations. This paper
explores the application of the Chain-of-Thought (CoT) reasoning model in
chemical engineering, starting from 30 experimental data points. By integrating
traditional surrogate models like Gaussian processes and random forests with
powerful LLMs such as DeepSeek-R1, a hierarchical architecture is proposed. Two
CoT-building methods, Large Language Model-Chain of Thought (LLM-CoT) and
Machine Learning-Large Language Model-Chain of Thought (ML-LLM-CoT), are
studied. The LLM-CoT combines local models DeepSeek-r1:14b and Qwen2:7b with
Ollama. The ML-LLM-CoT integrates a pre-trained Gaussian ML model with the
LLM-based CoT framework. Our results show that during construction, ML-LLM-CoT
is more efficient. It only has 2 points that require rethink and a total of 4
rethink times, while LLM-CoT has 5 points that need to be re-thought and 34
total rethink times. In predicting the solubility of 20 molecules with
dissimilar structures, the number of molecules with a prediction deviation
higher than 100\% for the Gaussian model, LLM-CoT, and ML-LLM-CoT is 7, 6, and
4 respectively. These results indicate that ML-LLM-CoT performs better in
controlling the number of high-deviation molecules, optimizing the average
deviation, and achieving a higher success rate in solubility judgment,
providing a more reliable method for chemical engineering and molecular
property prediction. This study breaks through the limitations of traditional
methods and offers new solutions for rapid property prediction and process
optimization in chemical engineering.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12383v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>The impact of job stability on monetary poverty in Italy: causal small
  area estimation</h3>
                    <p><strong>Authors:</strong> Katarzyna Reluga, Dehan Kong, Setareh Ranjbar, Nicola Salvati, Mark van der Laan</p>
                    <p>  Job stability - encompassing secure contracts, adequate wages, social
benefits, and career opportunities - is a critical determinant in reducing
monetary poverty, as it provides households with reliable income and enhances
economic well-being. This study leverages EU-SILC survey and census data to
estimate the causal effect of job stability on monetary poverty across Italian
provinces, quantifying its influence and analyzing regional disparities. We
introduce a novel causal small area estimation (CSAE) framework that integrates
global and local estimation strategies for heterogeneous treatment effect
estimation, effectively addressing data sparsity at the provincial level.
Furthermore, we develop a general bootstrap scheme to construct reliable
confidence intervals, applicable regardless of the method used for estimating
nuisance parameters. Extensive simulation studies demonstrate that our proposed
estimators outperform classical causal inference methods in terms of stability
while maintaining computational scalability for large datasets. Applying this
methodology to real-world data, we uncover significant relationships between
job stability and poverty across six Italian regions, offering critical
insights into regional disparities and their implications for evidence-based
policy design.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12376v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Bayesian inference from time series of allele frequency data using exact
  simulation techniques</h3>
                    <p><strong>Authors:</strong> Jaromir Sant, Paul A. Jenkins, Jere Koskela, Dario Spano</p>
                    <p>  A central statistical problem in population genetics is to infer evolutionary
and biological parameters such as the strength of natural selection and allele
age from DNA samples extracted from a contemporary population. That all samples
come only from the present-day has long been known to limit statistical
inference; there is potentially more information available if one also has
access to ancient DNA so that inference is based on a time-series of historical
changes in allele frequencies. We introduce a Markov Chain Monte Carlo (MCMC)
method for Bayesian inference from allele frequency time-series data based on
an underlying Wright--Fisher diffusion model of evolution, through which one
can infer the parameters of essentially any selection model including those
with frequency-dependent effects. The chief novelty is that we show this method
to be exact in the sense that it is possible to augment the state space
explored by MCMC with the unobserved diffusion trajectory, even though the
transition function of this diffusion is intractable. Through careful design of
a proposal distribution, we describe an efficient method in which updates to
the trajectory and accept/reject decisions are calculated without error. We
illustrate the method on data capturing changes in coat colour over the past
20,000 years, and find evidence to support previous findings that the mutant
alleles ASIP and MC1R responsible for changes in coat color have experienced
very strong, possibly overdominant, selection and further provide estimates for
the ages of these genes.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12279v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Crime in Proportions: Applying Compositional Data Analysis to European
  Crime Trends for 2022</h3>
                    <p><strong>Authors:</strong> Onur Batın Doğan, Fatma Sevinç Kurnaz</p>
                    <p>  This article investigates crime patterns across European countries in 2022
using Compositional Data Analysis (CoDA) to address limitations of traditional
statistical approaches in dealing with the relative nature of crime data.
Recognizing crime types as components of a whole, we employ CoDA to explore
relationships between different crime categories while respecting their
inherent interdependencies. The study utilizes k-means clustering to group
countries based on their crime profiles, identifying three distinct clusters
largely aligning with geographical locations. This clustering is visualized
through t-SNE and geographic mapping, revealing regional similarities. Further
analysis using Robust Principal Component Analysis on identified crime clusters
reveals insightful relationships between specific crime types, such as
homicide, smuggling, and financial crimes, and how their prevalence varies
across countries. The findings reveals distinct crime patterns across Europe,
highlighting regional commonalities while also highlighting divergences like
Norway and Latvia that deviate from their expected geographical
classifications. Moreover, the study identifies specific crime groups; for
example, it pairs countries high in corruption and smuggling, such as Austria,
with those countries that exhibit a higher relevance to homicide and smuggling,
such as Luxembourg. It also points to the presence of financial crimes like
fraud in countries such as Romania and Estonia.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12099v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Seamless short- to mid-term probabilistic wind power forecasting</h3>
                    <p><strong>Authors:</strong> Gabriel Dantas, Jethro Browell</p>
                    <p>  This paper presents a method for probabilistic wind power forecasting that
quantifies and integrates uncertainties from weather forecasts and
weather-to-power conversion. By addressing both uncertainty sources, the method
achieves state-of-the-art results for lead times of 6 to 162 hours, eliminating
the need for separate models for short- and mid-term forecasting. It also
improves short-term forecasts during high weather uncertainty periods, which
methods based on deterministic weather forecasts fail to capture. The study
reveals that weather-to-power uncertainty is more significant for short-term
forecasts, while weather forecast uncertainty dominates mid-term forecasts,
with the transition point varying between wind farms. Offshore farms typically
see this shift at shorter lead times than onshore ones. The findings are
supported by an extensive, reproducible case study comprising 73 wind farms in
Great Britain over five years.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.11960v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>On a Semiparametric Stochastic Volatility Model</h3>
                    <p><strong>Authors:</strong> Yudong Feng, Ashis Gangopadhyay</p>
                    <p>  This paper presents a novel approach to stochastic volatility (SV) modeling
by utilizing nonparametric techniques that enhance our ability to capture the
volatility of financial time series data, with a particular emphasis on the
non-Gaussian behavior of asset return distributions. Although traditional
parametric SV models can be useful, they often suffer from restrictive
assumptions regarding errors, which may inadequately represent extreme values
and tail behavior in financial returns. To address these limitations, we
propose two semiparametric SV models that use data to better approximate error
distributions. To facilitate the computation of model parameters, we developed
a Markov Chain Monte Carlo (MCMC) method for estimating model parameters and
volatility dynamics. Simulations and empirical tests on S&P 500 data indicate
that nonparametric models can minimize bias and variance in volatility
estimation, providing a more accurate reflection of market expectations about
volatility. This methodology serves as a promising alternative to conventional
parametric models, improving precision in financial risk assessment and
deepening our understanding of the volatility dynamics of financial returns.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.11954v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Searching for Low-Mass Exoplanets Amid Stellar Variability with a Fixed
  Effects Linear Model of Line-by-Line Shape Changes</h3>
                    <p><strong>Authors:</strong> Joseph Salzer, Jessi Cisewski-Kehe, Eric B. Ford, Lily L. Zhao</p>
                    <p>  The radial velocity (RV) method, also known as Doppler spectroscopy, is a
powerful technique for exoplanet discovery and characterization. In recent
years, progress has been made thanks to the improvements in the quality of
spectra from new extreme precision RV spectrometers. However, detecting the RV
signals of Earth-like exoplanets remains challenging, as the spectroscopic
signatures of low-mass planets can be obscured or confused with intrinsic
stellar variability. Changes in the shapes of spectral lines across time can
provide valuable information for disentangling stellar activity from true
Doppler shifts caused by low-mass exoplanets. In this work, we present a fixed
effects linear model to estimate RV signals that controls for changes in line
shapes by aggregating information from hundreds of spectral lines. Our
methodology incorporates a wild-bootstrap approach for modeling uncertainty and
cross-validation to control for overfitting. We evaluate the model's ability to
remove stellar activity using solar observations from the NEID spectrograph, as
the sun's true center-of-mass motion is precisely known. Including line
shape-change covariates reduces the RV root-mean-square errors by approximately
70% (from 1.919 m s$^{-1}$ to 0.575 m s$^{-1}$) relative to using only the
line-by-line Doppler shifts. The magnitude of the residuals is significantly
less than that from traditional CCF-based RV estimators and comparable to other
state-of-the-art methods for mitigating stellar variability.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.11930v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Forecasting Italian daily electricity generation disaggregated by
  geographical zones and energy sources using coherent forecast combination</h3>
                    <p><strong>Authors:</strong> Daniele Girolimetto, Tommaso Di Fonzo</p>
                    <p>  A novel approach is applied for improving forecast accuracy and achieving
coherence in forecasting the Italian daily energy generation time series. In
hierarchical frameworks such as national energy generation disaggregated by
geographical zones and energy sources, independently generated base forecasts
often result in inconsistencies across the constraints. We deal with this issue
through a coherent balanced multi-task forecast combination approach, which
combines unbiased forecasts from multiple experts while ensuring coherence.
Applied to the daily Italian electricity generation data, our method shows
superior accuracy compared to single-task base and combined forecasts, and a
state-of-the-art single-expert reconciliation technique, demonstrating to be an
effective approach to forecasting linearly constrained multiple time series.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.11878v1" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>