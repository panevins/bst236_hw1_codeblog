<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Search: Applied Statistics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Latest ArXiv Papers on Applied Statistics</h1>
    <p> This page displays the 10 most recents papers on <a href="https://arxiv.org/">ArXiv</a> in the category of "applied statistics". To see all most recent papers under this category, visit ArXiv's website <a href="https://arxiv.org/list/stat.AP/recent">here</a>. This page uses GitHub Actions and the ArXiv API to update each day at approximately midnight.</p>
    <p id="last-updated">Last updated: 2/27/2025, 7:44:49 PM</p>
    <button onclick="window.location.href='../index.html'" style="text-align: center;">Go to Homepage</button>
    <div id="papers">
                <div class="paper">
                    <h3>Enhancing Gradient-based Discrete Sampling via Parallel Tempering</h3>
                    <p><strong>Authors:</strong> Luxu Liang, Yuhang Jia, Feng Zhou</p>
                    <p>  While gradient-based discrete samplers are effective in sampling from complex
distributions, they are susceptible to getting trapped in local minima,
particularly in high-dimensional, multimodal discrete distributions, owing to
the discontinuities inherent in these landscapes. To circumvent this issue, we
combine parallel tempering, also known as replica exchange, with the discrete
Langevin proposal and develop the Parallel Tempering enhanced Discrete Langevin
Proposal (PTDLP), which are simulated at a series of temperatures. Significant
energy differences prompt sample swaps, which are governed by a Metropolis
criterion specifically designed for discrete sampling to ensure detailed
balance is maintained. Additionally, we introduce an automatic scheme to
determine the optimal temperature schedule and the number of chains, ensuring
adaptability across diverse tasks with minimal tuning. Theoretically, we
establish that our algorithm converges non-asymptotically to the target energy
and exhibits faster mixing compared to a single chain. Empirical results
further emphasize the superiority of our method in sampling from complex,
multimodal discrete distributions, including synthetic problems, restricted
Boltzmann machines, and deep energy-based models.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.19240v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Arctic teleconnection on climate and ozone pollution in the polar jet
  stream path of eastern US</h3>
                    <p><strong>Authors:</strong> K Shuvo Bakar, Sourish Das, Sudeep Shukla, Anirban Chakraborti</p>
                    <p>  Arctic sea ice is in reduction and has been a key significant indicator of
climate change. In this paper, we explore Arctic Sea ice extent data to
identify teleconnection with weather change in the polar and sub-tropical jet
stream intersection in eastern United States (US) and hence the potential
influence in ground level ozone pollution. Several statistical methods
including Bayesian techniques such as: spatio-temporal modelling and Bayesian
network are implemented to identify the teleconnection and also validated based
on theories in atmospheric science. We observe that the teleconnection is
relatively strong in autumn, winter and spring seasons compared to the summer.
Furthermore, the sudden decremental effect of Arctic sea-ice extent in
mid-2000s has a shifting influence in ozone pollutions compared to the previous
years. A similar downward shift in the Arctic sea-ice extent has been projected
in 2030. These findings indicate to initiate further strategic policies for the
Arctic influence, ozone concentrations together the seasonal and global
changing patterns of climate.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.19234v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Age Group Sensitivity Analysis of Epidemic Models: Investigating the
  Impact of Contact Matrix Structure</h3>
                    <p><strong>Authors:</strong> Zsolt Vizi, Evans Kiptoo Korir, Norbert Bogya, Csaba Rosztóczy, Géza Makay, Péter Boldog</p>
                    <p>  Understanding the role of different age groups in disease transmission is
crucial for designing effective intervention strategies. A key parameter in
age-structured epidemic models is the contact matrix, which defines the
interaction structure between age groups. However, accurately estimating
contact matrices is challenging, as different age groups respond differently to
surveys and are accessible through different channels. This variability
introduces significant epistemic uncertainty in epidemic models.
  In this study, we introduce the Age Group Sensitivity Analysis (AGSA) method,
a novel framework for assessing the impact of age-structured contact patterns
on epidemic outcomes. Our approach integrates age-stratified epidemic models
with Latin Hypercube Sampling (LHS) and the Partial Rank Correlation
Coefficient (PRCC) method, enabling a systematic sensitivity analysis of
age-specific interactions. Additionally, we propose a new sensitivity
aggregation technique that quantifies the contribution of each age group to key
epidemic parameters.
  By identifying the age groups to which the model is most sensitive, AGSA
helps pinpoint those that introduce the greatest epistemic uncertainty. This
allows for targeted data collection efforts, focusing surveys and empirical
studies on the most influential age groups to improve model accuracy. As a
result, AGSA can enhance epidemic forecasting and inform the design of more
effective and efficient public health interventions.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.19206v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Forecasting intermittent time series with Gaussian Processes and Tweedie
  likelihood</h3>
                    <p><strong>Authors:</strong> Stefano Damato, Dario Azzimonti, Giorgio Corani</p>
                    <p>  We introduce the use of Gaussian Processes (GPs) for the probabilistic
forecasting of intermittent time series. The model is trained in a Bayesian
framework that accounts for the uncertainty about the latent function and
marginalizes it out when making predictions. We couple the latent GP variable
with two types of forecast distributions: the negative binomial (NegBinGP) and
the Tweedie distribution (TweedieGP). While the negative binomial has already
been used in forecasting intermittent time series, this is the first time in
which a fully parameterized Tweedie density is used for intermittent time
series. We properly evaluate the Tweedie density, which is both zero-inflated
and heavy tailed, avoiding simplifying assumptions made in existing models. We
test our models on thousands of intermittent count time series. Results show
that our models provide consistently better probabilistic forecasts than the
competitors. In particular, TweedieGP obtains the best estimates of the highest
quantiles, thus showing that it is more flexible than NegBinGP.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.19086v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Predicting Long-term Urban Overheating and Their Mitigations from Nature
  Based Solutions Using Machine Learning and Field Measurements</h3>
                    <p><strong>Authors:</strong> Jiwei Zou, Lin Wang, Senwen Yang, Michael Lacasse,  Liangzhu,  Wang</p>
                    <p>  Urban overheating, exacerbated by climate change, threatens public health and
urban sustainability. Traditional approaches, such as numerical simulations and
field measurements, face challenges due to uncertainties in input data. This
study integrates field measurements with machine learning models to predict the
duration and severity of future urban overheating events, focusing on the role
of urban greening under different global warming (GW) scenarios. Field
measurements were conducted in summer 2024 at an office campus in Ottawa, a
cold-climate city. Microclimate data were collected from four locations with
varying levels of greenery: a large lawn without trees (Lawn), a parking lot
without greenery (Parking), an area with sparsely distributed trees (Tree), and
a fully covered forested area (Forest). Machine learning models, including
Artificial Neural Networks (ANN), Recurrent Neural Networks (RNN), and Long
Short-Term Memory (LSTM) networks, were trained on local microclimate data,
with LSTM achieving the best predictions. Four GW scenarios were analyzed,
corresponding to different Shared Socioeconomic Pathways (SSP) for 2050 and
2090. Results show that the Universal Thermal Climate Index (UTCI) at the
"Parking" location rises from about 27,\textdegree C under GW1.0 to
31,\textdegree C under GW3.5. Moreover, low health risk conditions (UTCI >
26,\textdegree C) increase across all locations due to climate change,
regardless of greenery levels. However, tree-covered areas such as "Tree" and
"Forest" effectively prevent extreme heat conditions (UTCI > 38.9,\textdegree
C). These findings highlight the crucial role of urban greening in mitigating
severe thermal stress and enhancing thermal comfort under future climate
scenarios.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.18647v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Attractiveness and equal treatment in a group draw</h3>
                    <p><strong>Authors:</strong> László Csató, Dóra Gréta Petróczy</p>
                    <p>  National teams from different continents can play against each other only in
afew sports competitions. Therefore, a reasonable aim is maximising the number
of intercontinental games in world cups, as done in basketball and football, in
contrast to handball and volleyball. However, this objective requires
additional draw constraints that imply the violation of equal treatment. In
addition, the standard draw mechanism is non-uniformly distributed on the set
of valid assignments, which may lead to further distortions. Our paper analyses
this novel trade-off between attractiveness and fairness through the example of
the 2025 World Men's Handball Championship. We introduce a measure of
inequality, which enables considering 32 sets of reasonable geographical
restrictions to determine the Pareto frontier. The proposed methodology can be
used by policy-makers to select the optimal set of draw constraints.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.18332v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Smart and Efficient IoT-Based Irrigation System Design: Utilizing a
  Hybrid Agent-Based and System Dynamics Approach</h3>
                    <p><strong>Authors:</strong> Taha Ahmadi Pargo, Mohsen Akbarpour Shirazi, Dawud Fadai</p>
                    <p>  Regarding problems like reduced precipitation and an increase in population,
water resource scarcity has become one of the most critical problems in
modern-day societies, as a consequence, there is a shortage of available water
resources for irrigation in arid and semi-arid countries. On the other hand, it
is possible to utilize modern technologies to control irrigation and reduce
water loss. One of these technologies is the Internet of Things (IoT). Despite
the possibility of using the IoT in irrigation control systems, there are
complexities in designing such systems. Considering this issue, it is possible
to use agent-oriented software engineering (AOSE) methodologies to design
complex cyber-physical systems such as IoT-based systems. In this research, a
smart irrigation system is designed based on Prometheus AOSE methodology, to
reduce water loss by maintaining soil moisture in a suitable interval. The
designed system comprises sensors, a central agent, and irrigation nodes. These
agents follow defined rules to maintain soil moisture at a desired level
cooperatively. For system simulation, a hybrid agent-based and system dynamics
model was designed. In this hybrid model, soil moisture dynamics were modeled
based on the system dynamics approach. The proposed model, was implemented in
AnyLogic computer simulation software. Utilizing the simulation model,
irrigation rules were examined. The system's functionality in automatic
irrigation mode was tested based on a 256-run, fractional factorial design, and
the effects of important factors such as soil properties on total irrigated
water and total operation time were analyzed. Based on the tests, the system
consistently irrigated nearly optimal water amounts in all tests. Moreover, the
results were also used to minimize the system's energy consumption by reducing
the system's operational time.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.18298v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Enhancing External Validity of Experiments with Ongoing Sampling</h3>
                    <p><strong>Authors:</strong> Chen Wang, Shichao Han, Shan Huang</p>
                    <p>  Participants in online experiments often enroll over time, which can
compromise sample representativeness due to temporal shifts in covariates. This
issue is particularly critical in A/B tests, online controlled experiments
extensively used to evaluate product updates, since these tests are
cost-sensitive and typically short in duration. We propose a novel framework
that dynamically assesses sample representativeness by dividing the ongoing
sampling process into three stages. We then develop stage-specific estimators
for Population Average Treatment Effects (PATE), ensuring that experimental
results remain generalizable across varying experiment durations. Leveraging
survival analysis, we develop a heuristic function that identifies these stages
without requiring prior knowledge of population or sample characteristics,
thereby keeping implementation costs low. Our approach bridges the gap between
experimental findings and real-world applicability, enabling product decisions
to be based on evidence that accurately represents the broader target
population. We validate the effectiveness of our framework on three levels: (1)
through a real-world online experiment conducted on WeChat; (2) via a synthetic
experiment; and (3) by applying it to 600 A/B tests on WeChat in a
platform-wide application. Additionally, we provide practical guidelines for
practitioners to implement our method in real-world settings.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.18253v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Differentially private synthesis of Spatial Point Processes</h3>
                    <p><strong>Authors:</strong> Dangchan Kim, Chae Young Lim</p>
                    <p>  This paper proposes a method to generate synthetic data for spatial point
patterns within the differential privacy (DP) framework. Specifically, we
define a differentially private Poisson point synthesizer (PPS) and Cox point
synthesizer (CPS) to generate synthetic point patterns with the concept of the
$\alpha$-neighborhood that relaxes the original definition of DP. We present
three example models to construct a differentially private PPS and CPS,
providing sufficient conditions on their parameters to ensure the DP given a
specified privacy budget. In addition, we demonstrate that the synthesizers can
be applied to point patterns on the linear network. Simulation experiments
demonstrate that the proposed approaches effectively maintain the privacy and
utility of synthetic data.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.18198v1" target="_blank">Read PDF</a></p>
                </div>
            
                <div class="paper">
                    <h3>Measuring Interlayer Dependence of Large Degrees in Multilayer
  Inhomogeneous Random Graphs</h3>
                    <p><strong>Authors:</strong> Zhuoye Han, Tiandong Wang</p>
                    <p>  Accurately capturing interlayer dependence is essential for understanding the
structure of complex multilayer networks. We propose an upper tail dependence
estimator specifically designed for multilayer networks, leveraging multilayer
inhomogeneous random graphs and multivariate regular variation to model
extremal dependence. We establish the consistency of the estimator and
demonstrate its practical effectiveness through real-data analysis of Reddit.
Our findings reveal how financial market dynamics influence user interactions
in the BitcoinMarkets subreddit and how seasonal trends shape engagement in
sports-related subreddits. This work provides a rigorous and practical tool for
quantifying extremal dependence across network layers, offering valuable
insights into risk propagation and interaction patterns in multilayer systems.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.17934v1" target="_blank">Read PDF</a></p>
                </div>
            </div>
    <script src="scripts/update-papers.js"></script>
</body>
<p></p>
<p></p>
<footer>
    <p>&copy; 2025 Pascale's Coding Blog. All rights reserved.</p>
    <p><a href="https://github.com/panevins" style="color:gold">@panevins</a> on GitHub</p>
</footer>

</html>